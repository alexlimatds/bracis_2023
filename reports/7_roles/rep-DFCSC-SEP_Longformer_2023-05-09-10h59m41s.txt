RESULTS REPORT - DFCSC-SEP
Model: Longformer
Encoder: allenai/longformer-base-4096
Dataset: malik
Evaluation: test set (5 random seeds)
Max sequence length: 1024
Min context length: 250
Batch size: 4
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h47m49s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.471223  0.033392  1.020485 0.083706   0.6691  0.0186   0.5354  0.0296   0.5377   0.0379
  2    1.008200  0.035789  0.867368 0.065503   0.7591  0.0242   0.6172  0.0364   0.6452   0.0453
  3    0.825540  0.024150  0.770396 0.043918   0.7801  0.0280   0.6786  0.0220   0.7074   0.0194
  4    0.725200  0.023519  0.747248 0.023387   0.7728  0.0101   0.7003  0.0062   0.7259   0.0037

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[355   4   2   2   0   0  29]
 [ 24 242   1  13   0   0  36]
 [ 12   2 138   4   0   0  45]
 [ 45   4   8 238   0   1 105]
 [ 78   2   0   7   0   0  35]
 [  3   1   4   0   0  13  16]
 [ 72  10   8  55   0   2 478]]
Epoch 2:
[[274  11  18  21   1   0  67]
 [  3 249   1  47   0   0  16]
 [  0   2 136  15   0   0  48]
 [ 34   4   2 354   0   0   7]
 [ 27   0   0  43   5   0  47]
 [  1   1   0   5   0  20  10]
 [  1   7   7 266   0   5 339]]
Epoch 3:
[[317   9   0   6   6   0  54]
 [  6 286   0   5   0   0  19]
 [  1   3 120   8   0   0  69]
 [ 37   6   1 280   0   0  77]
 [ 46   6   0   3  24   0  43]
 [  1   1   0   0   0  18  17]
 [  7  10   1  77   0   2 528]]
Epoch 4:
[[315   8   4   6   8   0  51]
 [  8 286   2   5   1   0  14]
 [  1   2 141   4   0   0  53]
 [ 37   6   5 297   1   1  54]
 [ 41   3   0   5  43   0  30]
 [  1   1   0   0   0  22  13]
 [  7  11   9  83   0   7 508]]
=> Iteration 1:
Epoch 1:
[[297   2  28  54   8   0   3]
 [ 15 198   1  71  10   0  21]
 [  8   1 132  43   0   0  17]
 [ 36   0   1 359   1   0   4]
 [ 36   0   7  65  12   0   2]
 [  1   0   6  13   2   9   6]
 [ 11   3   6 436   5   3 161]]
Epoch 2:
[[349   4   5   0   1   0  33]
 [ 20 278   0   0   0   0  18]
 [  8   5 129   0   0   0  59]
 [ 40  36   1 129   7   1 187]
 [ 85   5   3   0   9   0  20]
 [  2   1   1   0   0  22  11]
 [ 29  40   2  16   0   5 533]]
Epoch 3:
[[348   1   6   8   3   0  26]
 [ 16 267   1  14   0   0  18]
 [  9   2 133  13   0   0  44]
 [ 38   6   1 335   6   0  15]
 [ 64   3   2  15  22   1  15]
 [  2   1   0   0   0  23  11]
 [ 17  10   7 193   1   7 390]]
Epoch 4:
[[316   4  12   4  10   0  46]
 [ 10 269   1  10   3   0  23]
 [  0   2 141   6   0   0  52]
 [ 37   6   2 315   6   0  35]
 [ 39   3   6   9  46   1  18]
 [  1   1   0   0   0  23  12]
 [  8   9   8 123   0   6 471]]
=> Iteration 2:
Epoch 1:
[[349   0   2   2   0   0  39]
 [ 45 208   1   8   0   0  54]
 [ 10   1 139   3   2   0  46]
 [ 57   6   6 180   0   0 152]
 [ 64   0   0   0   0   0  58]
 [  7   0   0   0   0   8  22]
 [ 36   5  11  31   0   0 542]]
Epoch 2:
[[285  13   3   0  16   0  75]
 [  1 264   0   9   1   0  41]
 [  0   2 128   5   0   0  66]
 [ 34   7   1 224   2   0 133]
 [ 34   1   0   4  35   0  48]
 [  1   1   0   0   0  18  17]
 [  1  10   2  44   0   2 566]]
Epoch 3:
[[297  11   4   4  22   0  54]
 [  2 283   1   9   1   0  20]
 [  0   2 140   5   0   0  54]
 [ 38   8   3 274   9   1  68]
 [ 39   3   0   7  46   0  27]
 [  1   1   0   0   0  25  10]
 [  7  12   9  85   0   6 506]]
Epoch 4:
[[302   9   4   2  25   0  50]
 [  6 285   1   8   1   0  15]
 [  1   3 139   4   0   0  54]
 [ 38   8   3 265   9   1  77]
 [ 37   3   0   2  53   0  27]
 [  1   1   0   0   0  24  11]
 [  9  13   9  62   0   7 525]]
=> Iteration 3:
Epoch 1:
[[355   7   0  23   0   0   7]
 [ 29 246   0  34   0   0   7]
 [ 28   2 106  28   0   0  37]
 [ 64   7   0 319   0   0  11]
 [ 81   4   0  33   0   0   4]
 [ 17   2   0   6   0   1  11]
 [ 62  71   2 192   0   0 298]]
Epoch 2:
[[302   9   7   1   3   0  70]
 [  3 272   0   2   0   0  39]
 [  1   2 110   4   0   0  84]
 [ 36   9   1 208   0   0 147]
 [ 53   1   0   2   1   0  65]
 [  1   2   0   0   0  14  20]
 [  1   8   2  43   0   1 570]]
Epoch 3:
[[317   3  14   3  16   2  37]
 [  7 276   4   3   3   0  23]
 [  5   1 145   3   0   0  47]
 [ 39   8   7 267   9   1  70]
 [ 51   2   0   4  55   0  10]
 [  2   1   0   0   1  22  11]
 [ 10   8  12  63   1   6 525]]
Epoch 4:
[[326   2   9  11   8   2  34]
 [ 13 275   2  10   2   0  14]
 [  5   1 139   7   0   0  49]
 [ 41   8   3 311   8   1  29]
 [ 57   2   0  12  44   0   7]
 [  1   1   0   1   0  24  10]
 [ 11   6   9 119   1   7 472]]
=> Iteration 4:
Epoch 1:
[[349  17   3   3   1   0  19]
 [ 11 295   2   0   0   0   8]
 [ 13  16 151   4   0   0  17]
 [ 45  39  20 217   7   0  73]
 [ 83   9   0   0  11   0  19]
 [ 14   4   0   0   2   3  14]
 [ 61 127  32  48   4   0 353]]
Epoch 2:
[[315   1   7   4  11   0  54]
 [  9 269   1   5   3   0  29]
 [  0   2 135   6   0   0  58]
 [ 37   5   3 242   9   1 104]
 [ 39   0   0  12  45   1  25]
 [  1   0   0   0   0  22  14]
 [  1   6   7  76   1   3 531]]
Epoch 3:
[[329   2   4   3   5   0  49]
 [ 11 279   0   2   2   0  22]
 [  1   2 120   4   0   0  74]
 [ 37   7   1 250   9   0  97]
 [ 49   0   0   7  39   0  27]
 [  1   1   0   0   0  21  14]
 [  6   6   0  61   0   3 549]]
Epoch 4:
[[318   6   4   4  14   0  46]
 [  9 280   2   4   3   0  18]
 [  1   3 136   7   0   0  54]
 [ 37   7   3 272   9   0  73]
 [ 46   0   0  12  43   0  21]
 [  1   1   0   0   0  22  13]
 [  6   6   9  84   1   4 515]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.431252   0.924314   0.653446   0.581096    0.595604
Iteration 1    1.510152   1.129006   0.656858   0.505060    0.513989
Iteration 2    1.451083   0.932886   0.690189   0.538910    0.558827
Iteration 3    1.512080   1.099962   0.651764   0.501542    0.484622
Iteration 4    1.451549   1.016254   0.693329   0.550327    0.535253

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.990483   0.959693   0.754778   0.595755    0.608681
Iteration 1    1.076184   0.912860   0.735271   0.607815    0.616710
Iteration 2    0.971063   0.797954   0.795909   0.633839    0.684018
Iteration 3    1.000357   0.876191   0.733037   0.570816    0.602444
Iteration 4    1.002915   0.790141   0.776634   0.677574    0.714189

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.801209   0.829684   0.818784   0.648145    0.689909
Iteration 1    0.869761   0.815979   0.753182   0.665106    0.678993
Iteration 2    0.807455   0.743730   0.759825   0.699337    0.723169
Iteration 3    0.829109   0.719417   0.759512   0.707819    0.728604
Iteration 4    0.820165   0.743171   0.809419   0.672613    0.716100

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.700608   0.717316   0.790866   0.701518    0.730229
Iteration 1    0.768860   0.770191   0.768429   0.699527    0.724038
Iteration 2    0.709413   0.722362   0.765598   0.706825    0.730289
Iteration 3    0.723704   0.753561   0.762909   0.704785    0.723288
Iteration 4    0.723415   0.772807   0.776363   0.689039    0.721550

