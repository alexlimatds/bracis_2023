RESULTS REPORT - Cohan
Model: Longformer
Encoder: allenai/longformer-base-4096
Dataset: malik
Chunk layout: Cohan
Evaluation: test set (5 random seeds)
Max sequence length: 1024
Max sentence length: 85
Max sentences per chunk: 14
Batch size: 4
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 01h30m04s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.459866  0.033415  0.995437 0.053921   0.5786  0.0699   0.5208  0.0389   0.5157   0.0370
  2    1.019956  0.013742  0.899296 0.021174   0.6874  0.0299   0.6050  0.0194   0.6208   0.0171
  3    0.843035  0.015071  0.866012 0.016541   0.7251  0.0296   0.6065  0.0129   0.6381   0.0113
  4    0.727563  0.012572  0.836289 0.006865   0.7036  0.0145   0.6492  0.0085   0.6662   0.0079

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[253  17   9   0   0   0 113]
 [  3 230   2   3   0   0  78]
 [  0   4 131   0   0   0  66]
 [ 10   1   3  77   0   0 310]
 [ 29   0   0   0   0   0  93]
 [  2   0   0   1   0   0  34]
 [  5  10   4  18   0   0 588]]
Epoch 2:
[[306  13   5   5   7   0  56]
 [ 10 272   2  12   3   0  17]
 [  0   8 140   7   0   0  46]
 [ 30   8   2 260   7   0  94]
 [ 40   4   0   4  32   0  42]
 [  2   3   0   2   0  13  17]
 [ 18  19   5 136   7   7 433]]
Epoch 3:
[[329   7   0   3   4   0  49]
 [ 23 249   2   9   2   0  31]
 [  0   6 133   4   0   0  58]
 [ 32   6   2 220   4   0 137]
 [ 45   4   0   1  21   0  51]
 [  2   1   0   0   0  13  21]
 [ 29  13   5  88   0   8 482]]
Epoch 4:
[[311  12  12   6   8   0  43]
 [  5 286   2   7   2   0  14]
 [  0  10 147   8   0   0  36]
 [ 29   8   7 272   7   0  78]
 [ 37   8   0   7  41   0  29]
 [  2   3   0   0   0  16  16]
 [ 15  30   7 135   1   9 428]]
=> Iteration 1:
Epoch 1:
[[285  15  26  24   0   0  42]
 [ 23 244   8  17   1   0  23]
 [  0   6 150  15   0   0  30]
 [ 36   5  14 293   0   0  53]
 [ 43   8   0  43   4   0  24]
 [  3   3   7   8   0   0  16]
 [ 19  28  14 168   1   0 395]]
Epoch 2:
[[309  13  14   8   6   1  41]
 [ 14 270   3  10   2   0  17]
 [  4   8 142   6   0   0  41]
 [ 36   9   3 242   2   0 109]
 [ 51   8   0  11  17   5  30]
 [  6   4   0   2   0  10  15]
 [ 42  25   5 105   1   5 442]]
Epoch 3:
[[312   8  14   4   9   0  45]
 [ 31 259   5   7   2   0  12]
 [  4   8 143   3   0   0  43]
 [ 35   6   7 202   7   3 141]
 [ 45   6   0   3  42   4  22]
 [  4   3   0   0   0  13  17]
 [ 27  21   7  56  10   9 495]]
Epoch 4:
[[296  11  14   6  15   0  50]
 [  7 281   4   7   3   0  14]
 [  4  10 142   6   0   0  39]
 [ 33  10   6 265   7   2  78]
 [ 37   8   0   7  46   6  18]
 [  4   4   0   0   0  13  16]
 [ 14  30   7 118   4   8 444]]
=> Iteration 2:
Epoch 1:
[[296  16  16  14   0   0  50]
 [  9 233   6  30   0   0  38]
 [  3   6 146  10   0   0  36]
 [ 29   7  16 287   0   0  62]
 [ 34   3   0  37   0   0  48]
 [  4   1   0   7   0   0  25]
 [ 14  15   9 152   0   0 435]]
Epoch 2:
[[297  14  20  14   7   2  38]
 [  6 266   3  20   1   0  20]
 [  2   9 141  13   0   0  36]
 [ 32  11   2 306   4   0  46]
 [ 39   9   0  30  25   7  12]
 [  4   3   0   2   0  18  10]
 [ 16  17   2 167   0  12 411]]
Epoch 3:
[[290  12  14   4  11   0  61]
 [  6 259   2  13   1   0  35]
 [  1   7 133   6   0   0  54]
 [ 30   7   1 259   7   0  97]
 [ 40   8   0  16  34   0  24]
 [  4   2   0   0   0  13  18]
 [ 13  17   3 100   0   4 488]]
Epoch 4:
[[298  11  14   5  14   0  50]
 [  6 273   5   8   1   0  23]
 [  4   9 146   6   0   0  36]
 [ 34   9   8 265   7   1  77]
 [ 39   9   0  19  40   4  11]
 [  3   3   0   0   0  20  11]
 [ 14  24   6 106   0  12 463]]
=> Iteration 3:
Epoch 1:
[[303  18  19   5   3   0  44]
 [  7 284   4  11   0   0  10]
 [  0  13 156   7   0   0  25]
 [ 60  22  16 230   0   0  73]
 [ 67  18   0   7  12   0  18]
 [ 10   4   0   2   2   4  15]
 [ 45  51  16  65   0   1 447]]
Epoch 2:
[[321  14  13   6   6   0  32]
 [ 18 264   1  16   0   0  17]
 [  4  10 122  12   0   0  53]
 [ 41   7   1 283   1   0  68]
 [ 64   9   0  15  22   0  12]
 [  7   4   0   2   0   9  15]
 [ 43  40   2 104   0   3 433]]
Epoch 3:
[[300  12  14   3  12   0  51]
 [ 12 275   3   6   1   0  19]
 [  4  10 130   6   0   0  51]
 [ 34  13   2 186   7   0 159]
 [ 45   9   0   3  36   0  29]
 [  4   4   0   0   0   9  20]
 [ 20  25   2  40   0   0 538]]
Epoch 4:
[[310  12  14   9   8   0  39]
 [ 12 277   4  11   0   0  12]
 [  2  11 139   9   0   0  40]
 [ 34   9   5 286   3   0  64]
 [ 44   9   0  21  39   5   4]
 [  5   3   0   0   0  19  10]
 [ 26  28   6 128   5   9 423]]
=> Iteration 4:
Epoch 1:
[[309  16  15   6  16   0  30]
 [  5 274   6   7   5   0  19]
 [  4  10 143   4   1   0  39]
 [ 35  10  11 232   8   0 105]
 [ 52   7   0  15  27   0  21]
 [ 12   4   0   5   0   0  16]
 [ 39  49  10  91   6   0 430]]
Epoch 2:
[[274  16  23   7  14   1  57]
 [  4 265   8   9   1   0  29]
 [  0   9 166   4   0   0  22]
 [ 25   9  22 248   8   2  87]
 [ 34   6   0  13  26   9  34]
 [  3   4   2   1   0  14  13]
 [  0  16  33 103   0   8 465]]
Epoch 3:
[[295  12  14   5  12   0  54]
 [  6 267   5   9   1   0  28]
 [  3   9 135   5   0   0  49]
 [ 32   8   3 242   7   0 109]
 [ 39   7   0  10  43   1  22]
 [  5   3   0   0   0  13  16]
 [ 10  24   8  91   0   6 486]]
Epoch 4:
[[299  13  14   7  14   0  45]
 [  6 281   3   8   1   0  17]
 [  4  11 140   7   0   0  39]
 [ 32  12   7 260   7   0  83]
 [ 37   9   0  16  45   2  13]
 [  6   4   0   0   0  15  12]
 [ 10  32  10 106   1   6 460]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.449783   1.102461   0.547320   0.451117    0.456886
Iteration 1    1.521676   0.976259   0.575920   0.520132    0.503988
Iteration 2    1.420015   0.956452   0.501119   0.518646    0.507317
Iteration 3    1.454972   0.969980   0.709200   0.563293    0.561628
Iteration 4    1.452886   0.972034   0.559382   0.550666    0.548488

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.019173   0.884595   0.705790   0.613245    0.642469
Iteration 1    1.044494   0.904391   0.667119   0.581353    0.597157
Iteration 2    1.008626   0.890256   0.686662   0.630431    0.637045
Iteration 3    1.021989   0.938148   0.731848   0.583342    0.608224
Iteration 4    1.005497   0.879088   0.645579   0.616772    0.618977

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.827705   0.865639   0.725326   0.590323    0.623843
Iteration 1    0.866216   0.872098   0.678293   0.616905    0.636444
Iteration 2    0.847052   0.863248   0.734235   0.611119    0.648313
Iteration 3    0.848863   0.890216   0.770404   0.592184    0.628643
Iteration 4    0.825338   0.838859   0.717265   0.622004    0.653419

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.723027   0.832805   0.720767   0.651625    0.673231
Iteration 1    0.748267   0.834979   0.678177   0.635780    0.651035
Iteration 2    0.734903   0.826223   0.699388   0.660079    0.671695
Iteration 3    0.713471   0.845961   0.707538   0.654592    0.668278
Iteration 4    0.718150   0.841477   0.712117   0.643879    0.666716

