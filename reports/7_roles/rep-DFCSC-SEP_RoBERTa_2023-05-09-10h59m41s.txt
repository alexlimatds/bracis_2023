RESULTS REPORT - DFCSC-SEP
Model: RoBERTa
Encoder: roberta-base
Dataset: malik
Evaluation: test set (5 random seeds)
Max sequence length: 512
Min context length: 250
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h33m08s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.401176  0.027046  0.904094 0.026199   0.6624  0.0491   0.5578  0.0102   0.5641   0.0137
  2    0.928001  0.012623  0.816525 0.024931   0.7539  0.0201   0.6293  0.0140   0.6659   0.0123
  3    0.771298  0.009480  0.786734 0.012718   0.7345  0.0148   0.6759  0.0124   0.6969   0.0121
  4    0.680512  0.010317  0.770116 0.026008   0.7361  0.0108   0.6815  0.0080   0.7018   0.0081

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[328  13  15   4   1   0  31]
 [ 17 267   1  15   1   0  15]
 [  9   3 144   5   0   0  40]
 [ 59  23   6 222   0   1  90]
 [ 71  17   5   1   5   0  23]
 [ 16   1   2   0   3   4  11]
 [ 12  35  19  77   1   0 481]]
Epoch 2:
[[298   2  11   3  13   0  65]
 [  8 261   1   7   1   0  38]
 [  1   1 143   4   0   0  52]
 [ 35   9   5 237  11   1 103]
 [ 42   4   6   1  43   0  26]
 [  5   1   3   0   1  16  11]
 [  1   8  12  67   0   2 535]]
Epoch 3:
[[322   3  15   5  11   0  36]
 [ 15 272   2  14   0   0  13]
 [  3   4 151   5   1   0  37]
 [ 39  14   4 296  10   1  37]
 [ 51   3   5  13  37   0  13]
 [  4   1   1   0   2  20   9]
 [  1  35  24 125   5   3 432]]
Epoch 4:
[[289   4  11   6  20   0  62]
 [  7 271   1  15   2   0  20]
 [  1   2 146   7   1   0  44]
 [ 33  11   3 305  11   1  37]
 [ 36   4   6  14  47   0  15]
 [  3   1   1   0   0  22  10]
 [  0  21  16 125   2   4 457]]
=> Iteration 1:
Epoch 1:
[[304  14  12   4   0   0  58]
 [  2 267   0  13   0   0  34]
 [  4   3 133   7   0   0  54]
 [ 35   6   3 246   0   0 111]
 [ 41  30   3  15   0   0  33]
 [  4   1   1   3   0   3  25]
 [  2  13   5  95   0   0 510]]
Epoch 2:
[[288   9   7   1  17   0  70]
 [  4 275   0   6   0   0  31]
 [  0   3 118   6   0   0  74]
 [ 33   8   0 227   9   0 124]
 [ 35   7   0   8  43   0  29]
 [  4   1   0   0   7  14  11]
 [  0   9   1  75   1   1 538]]
Epoch 3:
[[314   3   9   5  15   1  45]
 [  6 272   1   6   1   0  30]
 [  4   3 140   7   0   0  47]
 [ 38   5   1 274  10   1  72]
 [ 49   4   0   9  41   0  19]
 [  3   1   0   0   3  21   9]
 [  0  10  10 106   1   2 496]]
Epoch 4:
[[319   2   9   5  13   1  43]
 [  8 275   1   6   1   0  25]
 [  4   3 143   7   0   0  44]
 [ 39   7   1 267   9   1  77]
 [ 56   4   0   8  37   0  17]
 [  1   2   0   0   2  23   9]
 [  0   9  11  99   1   5 500]]
=> Iteration 2:
Epoch 1:
[[331   3  10   8   1   0  39]
 [ 15 249   1  18   1   0  32]
 [  0   4 138   7   1   0  51]
 [ 43   5  10 268   4   0  71]
 [ 72   3   0  16   5   0  26]
 [  9   2   0   4   0   5  17]
 [  9   9  16  98   0   0 493]]
Epoch 2:
[[309   3   7   8   6   0  59]
 [ 11 243   1  16   0   0  45]
 [  0   2 137   6   0   0  56]
 [ 34   4   3 277   4   0  79]
 [ 54   0   0  12  20   0  36]
 [  3   1   0   2   0  20  11]
 [  1   3  11 105   0   5 500]]
Epoch 3:
[[297   4  11   6  15   0  59]
 [ 10 275   1  10   1   0  19]
 [  0   2 143   5   0   0  51]
 [ 35   9   3 286   8   1  59]
 [ 42   3   0  12  40   0  25]
 [  2   1   0   0   0  24  10]
 [  1  13  17 102   7   6 479]]
Epoch 4:
[[315   6  10   7  12   0  42]
 [ 11 280   1  10   0   0  14]
 [  0   4 142   6   0   0  49]
 [ 37   9   2 308   7   1  37]
 [ 47   3   0  13  39   0  20]
 [  3   1   0   0   0  24   9]
 [  1  16  17 124  10   6 451]]
=> Iteration 3:
Epoch 1:
[[331  14   1  13   0   0  33]
 [ 13 268   0  13   0   0  22]
 [  2   6 130   7   0   0  56]
 [ 37  12   0 262   0   0  90]
 [ 59  24   0  19   0   0  20]
 [  4   2   0   3   0   8  20]
 [  8  30   7  82   0   2 496]]
Epoch 2:
[[318   0   6   6  13   2  47]
 [ 17 243   1  16   1   0  38]
 [  1   2 139   3   0   0  56]
 [ 36   3   0 244  10   1 107]
 [ 54   0   0   8  34   5  21]
 [  3   0   0   0   0  18  16]
 [  4   3   6  88   4   8 512]]
Epoch 3:
[[304   6   7   5  16   0  54]
 [  9 282   1   5   1   0  18]
 [  0   6 146   4   0   0  45]
 [ 32   7   3 227  14   1 117]
 [ 45   8   0  14  35   4  16]
 [  2   2   0   0   0  18  15]
 [  2  15   4  62   5   7 530]]
Epoch 4:
[[310   3   2   4  17   0  56]
 [  7 281   1   7   1   0  19]
 [  0   6 146   4   0   0  45]
 [ 35   7   1 263  12   1  82]
 [ 48   8   0  13  37   4  12]
 [  4   2   0   0   1  19  11]
 [  4  12   7  76  10   8 508]]
=> Iteration 4:
Epoch 1:
[[281   7  15   9  36   0  44]
 [  3 256   0  26   8   0  23]
 [  0   6 131  18   0   0  46]
 [ 27   8   0 276  22   0  68]
 [ 34   3   2  17  38   0  28]
 [  6   3   0   2   0   0  26]
 [  4  14  10 139   4   0 454]]
Epoch 2:
[[289   6  11   6   9   0  71]
 [  3 270   1   9   1   0  32]
 [  0   5 136   8   0   0  52]
 [ 34  12   0 239   8   0 108]
 [ 42   5   0  12  26   0  37]
 [  3   2   0   0   0  12  20]
 [  0  16   9  71   0   1 528]]
Epoch 3:
[[287   3  12   4  39   0  47]
 [  6 285   1   2   7   0  15]
 [  4   7 145   4   0   0  41]
 [ 34  22   2 233  13   1  96]
 [ 37   3   0   0  70   0  12]
 [  3   3   1   0   0  19  11]
 [  0  26  17  65   3   7 507]]
Epoch 4:
[[316   3  10   4  18   0  41]
 [ 10 280   2   5   3   0  16]
 [  4   5 146   7   0   0  39]
 [ 34  17   1 249  11   1  88]
 [ 50   3   0  10  42   0  17]
 [  5   2   1   0   0  20   9]
 [  0  16  21  78   0   8 502]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.423600   0.893265   0.681454   0.552914    0.551240
Iteration 1    1.366897   0.941798   0.668932   0.541812    0.545866
Iteration 2    1.440087   0.864005   0.731086   0.564597    0.575903
Iteration 3    1.380598   0.920663   0.650508   0.571777    0.581550
Iteration 4    1.394698   0.900736   0.580018   0.557837    0.565780

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.937200   0.798804   0.759938   0.647073    0.684767
Iteration 1    0.916642   0.856912   0.773878   0.621391    0.667641
Iteration 2    0.947463   0.813000   0.759127   0.633442    0.666621
Iteration 3    0.914125   0.784966   0.715102   0.637801    0.664198
Iteration 4    0.924578   0.828944   0.761290   0.606649    0.646093

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.785168   0.805894   0.727994   0.672372    0.689276
Iteration 1    0.775242   0.797342   0.760323   0.676975    0.708255
Iteration 2    0.774765   0.781537   0.739942   0.685069    0.706309
Iteration 3    0.761851   0.774165   0.717021   0.654534    0.676781
Iteration 4    0.759462   0.774732   0.727255   0.690709    0.703671

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.688956   0.783982   0.739361   0.684692    0.706107
Iteration 1    0.680515   0.799880   0.751247   0.683744    0.708088
Iteration 2    0.694698   0.784888   0.742160   0.693445    0.710504
Iteration 3    0.667875   0.727125   0.721199   0.670268    0.689923
Iteration 4    0.670514   0.754707   0.726766   0.675360    0.694572

