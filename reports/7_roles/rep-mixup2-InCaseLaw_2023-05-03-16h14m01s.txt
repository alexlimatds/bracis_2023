RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 1.0
Augmentation rate: 1.0
Classes to augment: ['Fact', 'Argument', 'Statute', 'Precedent', 'RulingByLowerCourt', 'RulingByPresentCourt', 'RatioOfTheDecision']
Average number of mixup vectors by epoch: 14817.0
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h46m01s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.348929  0.010229  1.007888 0.006660   0.6325  0.0153   0.6002  0.0056   0.5986   0.0121
  2    1.150551  0.005606  1.024274 0.010112   0.6253  0.0195   0.6103  0.0089   0.6031   0.0094
  3    1.071952  0.002543  1.021821 0.006435   0.6252  0.0084   0.6064  0.0047   0.5989   0.0074
  4    1.022008  0.003748  1.034270 0.006471   0.6142  0.0062   0.6095  0.0030   0.5998   0.0039

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[287  12   6   4   9   4  70]
 [ 17 220   2  25   2   0  50]
 [  5   1 133  13   0   0  49]
 [ 37   8  11 242   6   0  97]
 [ 28   8   4  10  25  12  35]
 [  1   1   0   0   0  24  11]
 [ 38  26   6 128   1  10 416]]
Epoch 2:
[[273  13   3   3  23   4  73]
 [ 14 221   4  21   3   1  52]
 [  4   3 134   8   0   0  52]
 [ 33  11  10 202   9   1 135]
 [ 23   8   2   9  32  14  34]
 [  1   1   0   0   0  26   9]
 [ 34  40   5  72   4  12 458]]
Epoch 3:
[[299  13   6   4  12   3  55]
 [ 20 226   7  20   2   1  40]
 [  5   3 142   9   0   0  42]
 [ 37  15  15 208   4   0 122]
 [ 29  11   4  12  24  12  30]
 [  1   1   0   2   0  26   7]
 [ 44  68  15  72   5  11 410]]
Epoch 4:
[[305  13   4   4  14   3  49]
 [ 21 228   3  24   2   1  37]
 [  6   4 136   8   0   0  47]
 [ 37  17  10 218   5   1 113]
 [ 30  12   1  11  27  13  28]
 [  1   1   0   2   0  26   7]
 [ 56  86   8  79   6  11 379]]
=> Iteration 1:
Epoch 1:
[[311  12   7   6   5   4  47]
 [ 22 218   4  28   1   0  43]
 [  8   2 141  10   0   0  40]
 [ 44  12  15 229   3   0  98]
 [ 37  10   5  15  13  14  28]
 [  2   1   0   0   0  24  10]
 [ 61  61  13  94   1  11 384]]
Epoch 2:
[[308  11  10   0  19   5  39]
 [ 19 225   6  25   3   0  38]
 [ 10   2 138   9   0   0  42]
 [ 38  12  14 210   9   0 118]
 [ 29  13   5  10  29  14  22]
 [  1   1   0   0   0  25  10]
 [ 62  75  10  73  13  11 381]]
Epoch 3:
[[315  14   1   6   9   4  43]
 [ 23 221   4  26   1   1  40]
 [  8   3 136  12   0   0  42]
 [ 35  13  10 213   6   0 124]
 [ 29  13   2  15  21  14  28]
 [  1   1   0   2   0  25   8]
 [ 64  51   9  84   8  11 398]]
Epoch 4:
[[318  13   1   4  14   3  39]
 [ 22 226   4  26   2   1  35]
 [  9   3 137  12   0   0  40]
 [ 37  12  13 226   6   0 107]
 [ 31  14   4  11  26  14  22]
 [  1   1   0   2   0  25   8]
 [ 60  77  12  95  11  11 359]]
=> Iteration 2:
Epoch 1:
[[300  11   4   7  12   4  54]
 [ 19 215   3  32   2   0  45]
 [  9   2 139  13   0   0  38]
 [ 39   7  17 244   8   0  86]
 [ 28   7   5  17  25  13  27]
 [  1   1   0   0   0  24  11]
 [ 59  34  16 128   2   7 379]]
Epoch 2:
[[319   5   4   2  18   4  40]
 [ 28 213   5  19   3   1  47]
 [  9   3 140   4   0   0  45]
 [ 41   8  15 202   7   0 128]
 [ 31   4   4   5  39  15  24]
 [  1   0   0   0   0  26  10]
 [ 71  38  11  60   7  14 424]]
Epoch 3:
[[316   9   3   5  13   3  43]
 [ 24 213   3  28   2   0  46]
 [ 12   1 133   4   0   0  51]
 [ 37  10  11 216   6   0 121]
 [ 33   6   4  10  30  13  26]
 [  1   0   0   0   0  26  10]
 [ 69  33   8  83   6  11 415]]
Epoch 4:
[[314  12   3   6  13   3  41]
 [ 20 223   4  26   2   0  41]
 [  9   5 137   9   0   0  41]
 [ 37  11  12 224   6   0 111]
 [ 32  12   3  11  27  14  23]
 [  1   1   0   0   0  26   9]
 [ 64  62  10  94   6  11 378]]
=> Iteration 3:
Epoch 1:
[[296   8  10   5   8   4  61]
 [ 20 216   6  27   1   0  46]
 [  6   2 137   6   0   0  50]
 [ 45  10  13 216   2   0 115]
 [ 34   7   7   6  29  12  27]
 [  2   1   0   0   0  24  10]
 [ 53  39  12  87   1   6 427]]
Epoch 2:
[[310  12   6  11  10   3  40]
 [ 18 229   6  31   2   0  30]
 [  6   5 143   9   0   0  38]
 [ 36  12  15 228   3   0 107]
 [ 29  13   6  22  21  13  18]
 [  1   0   0   0   0  26  10]
 [ 53  65  16 104   3  11 373]]
Epoch 3:
[[299  16   3   6  11   4  53]
 [ 24 220   4  29   1   1  37]
 [  7   2 133   9   0   0  50]
 [ 39  11  13 225   3   0 110]
 [ 32   8   4  12  25  14  27]
 [  1   1   0   2   0  27   6]
 [ 56  57   5  94   4  11 398]]
Epoch 4:
[[298  16   3   4  16   3  52]
 [ 24 228   3  27   2   1  31]
 [  7   5 137   9   0   0  43]
 [ 37  12  14 217   4   0 117]
 [ 30   9   3  11  30  13  26]
 [  1   0   0   2   0  26   8]
 [ 54  68   7  86   9  11 390]]
=> Iteration 4:
Epoch 1:
[[261  14   2   6  20   5  84]
 [ 13 216   4  29   2   1  51]
 [  6   3 138   9   0   0  45]
 [ 27  12  11 215  10   1 125]
 [ 19  10   3  15  28  15  32]
 [  1   0   0   0   0  26  10]
 [ 30  25   5  94   1  13 457]]
Epoch 2:
[[309  11   0   1   9   5  57]
 [ 22 217   1  28   2   1  45]
 [ 10   3 123   5   0   0  60]
 [ 40  10   7 190   4   0 150]
 [ 29   9   1  11  25  14  33]
 [  1   0   0   2   0  26   8]
 [ 48  33   2  62   6  11 463]]
Epoch 3:
[[296  15   8   2   5   4  62]
 [ 21 225   4  23   2   1  40]
 [  4   2 144   6   0   0  45]
 [ 35  12  15 188   5   1 145]
 [ 31   8   3  13  20  16  31]
 [  1   0   0   0   0  26  10]
 [ 39  59   7  65   4  11 440]]
Epoch 4:
[[318  14   0   0  12   3  45]
 [ 26 225   4  26   2   1  32]
 [  8   3 141   8   0   0  41]
 [ 37  11  13 204   5   0 131]
 [ 31  12   2   9  26  16  26]
 [  1   0   0   2   0  26   8]
 [ 46  76   7  69  13  11 403]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.333161   1.004707   0.645613   0.601814    0.606692
Iteration 1    1.356503   1.019362   0.614509   0.589345    0.575658
Iteration 2    1.340761   1.006694   0.620947   0.600811    0.598782
Iteration 3    1.354230   1.009506   0.654945   0.604064    0.609760
Iteration 4    1.359990   0.999171   0.626720   0.605071    0.602200

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.145964   1.011627   0.630066   0.609143    0.607601
Iteration 1    1.161298   1.036424   0.593929   0.604425    0.591196
Iteration 2    1.147010   1.030066   0.635539   0.626980    0.618036
Iteration 3    1.150764   1.030462   0.615454   0.609594    0.595636
Iteration 4    1.147717   1.012790   0.651481   0.601307    0.603050

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.068245   1.010340   0.618190   0.608363    0.598971
Iteration 1    1.075713   1.029182   0.614420   0.599333    0.591446
Iteration 2    1.071885   1.019988   0.638625   0.613303    0.612041
Iteration 3    1.070468   1.024712   0.627908   0.607599    0.599599
Iteration 4    1.073448   1.024881   0.626881   0.603287    0.592311

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.021995   1.034443   0.616710   0.607179    0.598257
Iteration 1    1.027383   1.042020   0.601836   0.604970    0.592888
Iteration 2    1.016398   1.039687   0.618118   0.610818    0.601853
Iteration 3    1.019915   1.023666   0.617602   0.611010    0.603591
Iteration 4    1.024352   1.031533   0.616924   0.613441    0.602281

