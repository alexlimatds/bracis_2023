RESULTS REPORT (PE S)
Model: RoBERTa
Encoder: roberta-base
Evaluation: test set (5 random seeds)
Combination: S
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h44m23s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.661262  0.048426  1.343114 0.046124   0.5239  0.0308   0.4702  0.0187   0.4805   0.0161
  2    1.276915  0.033940  1.220546 0.035671   0.5680  0.0187   0.5324  0.0131   0.5417   0.0128
  3    1.123879  0.022949  1.212995 0.033293   0.5668  0.0172   0.5560  0.0174   0.5544   0.0093
  4    1.030110  0.020990  1.224303 0.031743   0.5727  0.0116   0.5614  0.0116   0.5629   0.0101

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[295   8   6  14  20   9  40]
 [ 42 183   6  43   2   1  39]
 [ 27   9 133   6   0   2  24]
 [ 56  22  23 197   3  17  83]
 [ 55  15   2  14   9  13  14]
 [ 16   0   0   2   0  14   5]
 [169  33  20 104  17  17 265]]
Epoch 2:
[[259  15   5  21  26   5  61]
 [ 15 204   6  50   2   0  39]
 [  6  10 134  13   0   1  37]
 [ 39  15  17 230   4   5  91]
 [ 39  16   4  19  21  10  13]
 [  7   0   0   2   2  16  10]
 [ 64  33  15 175   9   7 322]]
Epoch 3:
[[269  20   4  11  26   3  59]
 [ 17 213   8  36   2   0  40]
 [ 12   9 131   8   1   0  40]
 [ 46  24  15 204   7   0 105]
 [ 34  26   1  15  24   7  15]
 [  5   0   0   3   3  15  11]
 [ 67  46  13 118  13   4 364]]
Epoch 4:
[[272  17   5  11  24   3  60]
 [ 18 207   8  35   3   0  45]
 [ 11   8 135   6   1   0  40]
 [ 42  24  17 195   6   2 115]
 [ 32  22   3  12  25   9  19]
 [  4   0   0   3   2  17  11]
 [ 65  39  20 102  13   7 379]]
=> Iteration 1:
Epoch 1:
[[257  17   0  14  24   5  75]
 [ 40 181   2  22   8   0  63]
 [ 13   9 120   2   0   0  57]
 [ 38   8  11 150  15   1 178]
 [ 48   8   1  12  21   1  31]
 [  6   0   1   2  10   9   9]
 [ 35  76   4  61  39   3 407]]
Epoch 2:
[[250  24   1  16  33   6  62]
 [ 25 212   2  22   7   0  48]
 [ 11  15 129   6   0   0  40]
 [ 40  19  15 183   9   1 134]
 [ 31  14   2  12  36   5  22]
 [  2   0   1   1   6  15  12]
 [ 28  75   6  87  29   5 395]]
Epoch 3:
[[262  19   8  19  19   9  56]
 [ 25 206  12  26   5   2  40]
 [  6  13 148   6   0   4  24]
 [ 40  17  28 186   9   4 117]
 [ 29  12   4  14  30  11  22]
 [  1   0   1   1   1  25   8]
 [ 28  59  25  89   9  17 398]]
Epoch 4:
[[263  14   3  21  21   6  64]
 [ 27 204   5  25   5   0  50]
 [  8  13 133   8   0   2  37]
 [ 41  15  15 191   5   1 133]
 [ 31  11   1  14  35   8  22]
 [  1   0   1   2   2  21  10]
 [ 32  46  10  91  11  11 424]]
=> Iteration 2:
Epoch 1:
[[174  32   6   7   4   2 167]
 [ 10 174   1  27   0   0 104]
 [  1   4 111   5   0   0  80]
 [ 19  21  15 157   7   0 182]
 [ 13  15   4   9   6   3  72]
 [  1   0   3   1   0  10  22]
 [ 24  26  10  34  11   5 515]]
Epoch 2:
[[247  52   6  12  13   1  61]
 [ 18 214   2  31   0   0  51]
 [ 11   7 135  10   0   0  38]
 [ 33  37  20 197   8   0 106]
 [ 35  27   6  16  17   1  20]
 [  5   1   2   1   0  12  16]
 [ 52  63  19  64  14   2 411]]
Epoch 3:
[[255  33   6  14  23   1  60]
 [ 19 207   5  29   2   0  54]
 [  8   5 139  10   2   0  37]
 [ 30  31  18 210  10   2 100]
 [ 35  20   3  21  22   4  17]
 [  2   0   2   1   0  18  14]
 [ 60  47  19  64  23   6 406]]
Epoch 4:
[[256  31   6  14  23   2  60]
 [ 16 207   5  30   1   0  57]
 [  9   8 139   8   0   0  37]
 [ 33  22  13 210   9   3 111]
 [ 32  18   3  16  27   6  20]
 [  2   0   2   1   0  18  14]
 [ 45  46  20  56  21   9 428]]
=> Iteration 3:
Epoch 1:
[[250  34   2  29  14   5  58]
 [ 20 214   2  28   2   0  50]
 [ 16  13 128  15   0   1  28]
 [ 37  37  15 221   9   1  81]
 [ 34  19   1  20  17   6  25]
 [  6   1   0   3   4  12  11]
 [ 44  78   5 165   6   6 321]]
Epoch 2:
[[249  16   3  17  19   5  83]
 [ 20 195   6  24   4   0  67]
 [  6   5 138   4   0   2  46]
 [ 40  16  20 204   6   6 109]
 [ 32  11   0  11  26   7  35]
 [  4   0   0   4   2  19   8]
 [ 28  23  10 126   4   7 427]]
Epoch 3:
[[281  16   9   8  14   4  60]
 [ 25 208  10  20   3   0  50]
 [  6   5 148   4   0   0  38]
 [ 47  25  23 194   4   0 108]
 [ 44  11   4  11  20   5  27]
 [  3   0   1   2   2  19  10]
 [ 36  48  18 110   2   3 408]]
Epoch 4:
[[267  23   6   9  20   6  61]
 [ 25 207   8  20   4   0  52]
 [  7   7 140   6   0   2  39]
 [ 40  28  20 200   7   0 106]
 [ 36  12   1  11  26   8  28]
 [  4   0   0   1   2  21   9]
 [ 32  50  14 107   4   7 411]]
=> Iteration 4:
Epoch 1:
[[292   5   4   6  20   5  60]
 [ 61 164   0  25   4   2  60]
 [  9   1 113   2   2   0  74]
 [ 57  15  12 122  21   4 170]
 [ 43   4   4   2  31   3  35]
 [  9   1   0   1   4  11  11]
 [ 92  35   6  98  18   9 367]]
Epoch 2:
[[293  10   2   8  22   6  51]
 [ 36 195   4  29   2   0  50]
 [ 11   4 127   4   0   0  55]
 [ 47  20  15 187   9   1 122]
 [ 40  11   4   4  32   5  26]
 [  4   1   0   2   0  18  12]
 [ 71  44  14 122  12   7 355]]
Epoch 3:
[[287  12   3  10  24   5  51]
 [ 36 208   5  29   3   1  34]
 [  7   6 135   3   0   1  49]
 [ 49  25  16 183   8   2 118]
 [ 42  12   5   9  29   6  19]
 [  3   1   0   2   0  23   8]
 [ 56  77  16 121   9  11 335]]
Epoch 4:
[[272  17   5  16  24   4  54]
 [ 22 210   6  38   5   2  33]
 [  7   5 138   6   0   0  45]
 [ 39  23  19 208   8   0 104]
 [ 31  14   5  14  34   7  17]
 [  3   1   0   2   0  23   8]
 [ 43  71  22 138  10   8 333]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.657371   1.415864   0.467893   0.480111    0.458973
Iteration 1    1.635907   1.297539   0.539517   0.466579    0.489545
Iteration 2    1.731741   1.317420   0.559733   0.440246    0.468122
Iteration 3    1.589410   1.306276   0.531996   0.497168    0.504999
Iteration 4    1.691882   1.378471   0.520416   0.466987    0.480939

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.276564   1.268484   0.535000   0.523754    0.523690
Iteration 1    1.254488   1.200924   0.563690   0.534183    0.545453
Iteration 2    1.306427   1.182555   0.588126   0.513071    0.530840
Iteration 3    1.226841   1.192302   0.583293   0.551059    0.559138
Iteration 4    1.320255   1.258464   0.569907   0.539928    0.549498

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.131176   1.250360   0.559029   0.529324    0.540073
Iteration 1    1.111449   1.214124   0.551283   0.582686    0.555569
Iteration 2    1.142726   1.160506   0.570243   0.548174    0.556548
Iteration 3    1.085586   1.194580   0.598624   0.560774    0.568752
Iteration 4    1.148457   1.245404   0.554678   0.559100    0.550861

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.033731   1.265302   0.553019   0.539663    0.543265
Iteration 1    1.019087   1.193877   0.586391   0.569620    0.572401
Iteration 2    1.049708   1.192259   0.576694   0.559422    0.565081
Iteration 3    0.995641   1.210810   0.580071   0.567106    0.567685
Iteration 4    1.052383   1.259267   0.567398   0.570974    0.566195

