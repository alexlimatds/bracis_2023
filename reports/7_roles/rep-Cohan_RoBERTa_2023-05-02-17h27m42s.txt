RESULTS REPORT
Model: RoBERTa
Encoder: roberta-base
Chunk layout: Cohan
Evaluation: test set (5 random seeds)
Max sequence length: 512
Max sentence length: 85
Max sentences per chunk: 7
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h32m46s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.536765  0.037489  1.120392 0.126383   0.5511  0.0565   0.4835  0.0381   0.4844   0.0456
  2    1.124307  0.035985  0.949983 0.030230   0.7007  0.0509   0.5503  0.0195   0.5747   0.0217
  3    0.965428  0.026137  0.883967 0.039461   0.6921  0.0127   0.6106  0.0152   0.6320   0.0162
  4    0.873984  0.025137  0.883751 0.019568   0.7024  0.0092   0.6099  0.0059   0.6364   0.0076

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[303  20  13   0   0   0  56]
 [ 20 241   7   6   0   0  42]
 [  4   7 116   0   0   0  74]
 [ 39  31   1 121   0   0 209]
 [ 56  30   0   0   0   0  36]
 [  4   5   0   1   0   0  27]
 [ 30  39   0  23   0   0 533]]
Epoch 2:
[[325   2   8   1   2   0  54]
 [ 20 246   3  14   0   0  33]
 [  3   9 112   7   0   0  70]
 [ 37  18   0 225   1   0 120]
 [ 62   4   0  12   9   0  35]
 [  6   3   0   4   0   5  19]
 [ 22  43   0  67   0   0 493]]
Epoch 3:
[[331   2   9   1   8   0  41]
 [ 21 259   4  12   0   0  20]
 [  7  10 137   6   0   0  41]
 [ 36  24   0 218   7   2 114]
 [ 56   7   0   7  31   5  16]
 [  6   4   0   1   2  15   9]
 [ 43  56   9  70  10   2 435]]
Epoch 4:
[[321   2   8   3   7   0  51]
 [ 20 256   3  14   0   0  23]
 [  3   9 124   6   0   0  59]
 [ 36  19   0 228   7   0 111]
 [ 51   4   0  11  26   6  24]
 [  6   3   0   1   1  16  10]
 [ 25  38   1  83   5   2 471]]
=> Iteration 1:
Epoch 1:
[[369   0   8   1   0   0  14]
 [133 138   6  11   0   0  28]
 [ 28   0 142   0   0   0  31]
 [137   1  10 174   0   0  79]
 [102   0   0   0   0   0  20]
 [ 26   0   0   0   0   0  11]
 [238   4  18  33   0   0 332]]
Epoch 2:
[[240   8   9   1   2   1 131]
 [  1 269   0   7   0   0  39]
 [  0   7 102   3   0   0  89]
 [ 21  14   0 156   9   0 201]
 [ 22   2   0   6   9   5  78]
 [  1   3   0   2   0  14  17]
 [  6  21   0  35   0   2 561]]
Epoch 3:
[[330   3  16   0   9   0  34]
 [ 22 260   2  11   0   0  21]
 [  0  10 139   7   0   0  45]
 [ 39  15   1 227   7   1 111]
 [ 54   2   0  14  39   1  12]
 [  4   3   0   1   1  18  10]
 [ 28  36  13  83   7  11 447]]
Epoch 4:
[[317   6  14   2   7   0  46]
 [ 14 266   2  12   0   0  22]
 [  0  10 136   7   0   0  48]
 [ 37  14   0 236   6   0 108]
 [ 45   6   0  15  38   1  17]
 [  4   3   0   1   5  12  12]
 [ 16  44   7  87   5   6 460]]
=> Iteration 2:
Epoch 1:
[[324   2   8   0   0   0  58]
 [ 21 216   7   7   0   0  65]
 [  0   0 107   1   0   0  93]
 [ 46  10   2 117   0   0 226]
 [ 63   8   0   0   0   0  51]
 [  6   0   0   1   0   0  30]
 [ 43   5   4  28   0   0 545]]
Epoch 2:
[[325   2  14   9   2   1  39]
 [ 18 256   6  19   0   0  17]
 [  0   8 139   6   0   1  47]
 [ 40  14   9 237   0   0 101]
 [ 59   9   0  18   3   3  30]
 [  8   3   0   4   0   9  13]
 [ 29  42  12 122   3   1 416]]
Epoch 3:
[[323   2  12   6   6   0  43]
 [ 22 253   3  20   0   0  18]
 [  0   8 139   6   0   0  48]
 [ 36   8   9 256   0   0  92]
 [ 57   6   0  16  11   1  31]
 [  3   3   0   3   0  15  13]
 [ 22  30   8 145   2   5 413]]
Epoch 4:
[[320   3  10   4   6   0  49]
 [ 15 263   2  15   0   0  21]
 [  0  10 132   5   0   0  54]
 [ 36  12   0 242   0   0 111]
 [ 58   9   0  14  17   1  23]
 [  3   3   0   1   0  18  12]
 [ 21  47   3 114   2   6 432]]
=> Iteration 3:
Epoch 1:
[[324   5   7  12   1   0  43]
 [ 14 254   2  22   0   0  24]
 [  3   9 140   8   0   0  41]
 [ 37  15   2 269   2   0  76]
 [ 46  15   0  23   0   0  38]
 [  4   3   0   5   0   5  20]
 [ 42  66   4 144   0   3 366]]
Epoch 2:
[[310   2  13   0  15   1  51]
 [ 37 227   3  10   2   0  37]
 [  0   6 148   0   0   0  47]
 [ 38  13   2 189  12   1 146]
 [ 48   0   0   7  28   2  37]
 [  4   2   0   1   5  12  13]
 [ 30  19  11  46   2   7 510]]
Epoch 3:
[[304   5   8  14  13   0  48]
 [  9 268   2  19   2   0  16]
 [  0   8 134   8   0   0  51]
 [ 36  10   1 276   5   0  73]
 [ 36   8   0  23  29   2  24]
 [  4   4   0   1   2  15  11]
 [ 11  33   4 157   5   5 410]]
Epoch 4:
[[312   3   8   7  14   0  48]
 [ 16 262   3  12   2   0  21]
 [  0   8 137   7   0   0  49]
 [ 37  10   0 254  10   0  90]
 [ 45   4   0  19  32   2  20]
 [  4   4   0   1   3  14  11]
 [ 25  32   4  98   5   7 454]]
=> Iteration 4:
Epoch 1:
[[296   2  13   5   1   0  75]
 [ 17 223   3  23   3   0  47]
 [  0   7 132   4   0   0  58]
 [ 34  10   0 213   0   0 144]
 [ 36   1   0  19  18   0  48]
 [  4   2   0   4   0   0  27]
 [  4   6   2  60   1   0 552]]
Epoch 2:
[[260   8   8   6   5   0 105]
 [  8 253   4  21   3   0  27]
 [  0   8 126   7   0   0  60]
 [ 24  15   0 239   6   0 117]
 [ 32   6   0  17  19   1  47]
 [  4   3   0   2   0   7  21]
 [  4  12   2  72   1   0 534]]
Epoch 3:
[[302   2  11   3   9   0  65]
 [ 17 253   4  15   1   0  26]
 [  0   8 148   3   0   0  42]
 [ 33  12   1 228   5   0 122]
 [ 48   0   0  14  24   2  34]
 [  4   3   0   1   0  15  14]
 [ 11  21   7  69   1   6 510]]
Epoch 4:
[[304   3   7   3  12   0  63]
 [ 17 260   3  16   2   0  18]
 [  0   9 134   5   0   0  53]
 [ 36  16   0 234   7   0 108]
 [ 49   2   0  13  34   1  23]
 [  4   3   0   1   1  15  13]
 [ 11  36   3  78   4   6 487]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.564492   1.162328   0.500596   0.466754    0.457772
Iteration 1    1.551724   1.340250   0.504738   0.435660    0.428659
Iteration 2    1.578977   1.097025   0.520911   0.458026    0.459359
Iteration 3    1.476303   1.021158   0.581228   0.531201    0.529504
Iteration 4    1.512331   0.981201   0.648274   0.525633    0.546849

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.160719   0.974643   0.768832   0.531940    0.553873
Iteration 1    1.148858   0.990393   0.700831   0.529964    0.564812
Iteration 2    1.146713   0.904372   0.627246   0.550744    0.554682
Iteration 3    1.065757   0.945652   0.665219   0.583806    0.607962
Iteration 4    1.099489   0.934854   0.741318   0.555157    0.592414

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.984840   0.961574   0.676306   0.606392    0.625883
Iteration 1    0.971064   0.874398   0.687688   0.634801    0.651330
Iteration 2    0.998726   0.856610   0.687698   0.587275    0.604069
Iteration 3    0.926347   0.870542   0.694078   0.611095    0.636520
Iteration 4    0.946164   0.856712   0.714790   0.613438    0.641969

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.890456   0.883998   0.699952   0.601949    0.629879
Iteration 1    0.874169   0.853074   0.700696   0.612484    0.639392
Iteration 2    0.911597   0.893648   0.712904   0.603692    0.625779
Iteration 3    0.847456   0.912246   0.687146   0.615302    0.639850
Iteration 4    0.846243   0.875786   0.711084   0.615971    0.647165

