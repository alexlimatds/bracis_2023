RESULTS REPORT - DFCSC-CLS
Model: RoBERTa
Encoder: roberta-base
Evaluation: test set (5 random seeds)
Max sequence length: 512
Min context length: 250
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h33m27s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.424800  0.013846  0.944459 0.058283   0.6238  0.0994   0.5414  0.0314   0.5478   0.0447
  2    0.948281  0.010950  0.862273 0.046485   0.7370  0.0389   0.6124  0.0168   0.6427   0.0128
  3    0.781006  0.011637  0.792675 0.027162   0.7452  0.0220   0.6674  0.0286   0.6900   0.0220
  4    0.692442  0.006715  0.766003 0.014799   0.7350  0.0123   0.6785  0.0091   0.6981   0.0079

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[326   8   5   6   0   0  47]
 [ 17 257   0  12   0   0  30]
 [  4   5 119  11   0   0  62]
 [ 38   8   0 257   0   0  98]
 [ 67   9   0  18   0   0  28]
 [  9   2   0   4   0   0  22]
 [  8  22   0  97   0   0 498]]
Epoch 2:
[[291  11   7   4  15   0  64]
 [  6 292   0   6   3   0   9]
 [  4  12 120   7   0   0  58]
 [ 31  36   0 221  10   1 102]
 [ 34   7   0  11  43   4  23]
 [  2   3   0   2   0  18  12]
 [  0 112   2  74   1   3 433]]
Epoch 3:
[[300   6   9   4  14   0  59]
 [  7 281   2   6   2   0  18]
 [  4   3 135   7   0   0  52]
 [ 34  19   1 244  10   1  92]
 [ 45   3   0  13  38   0  23]
 [  3   2   0   0   0  16  16]
 [  0  22  11  83   2   1 506]]
Epoch 4:
[[308   4   9   4  15   0  52]
 [  8 279   3   6   3   0  17]
 [  5   2 135   7   0   0  52]
 [ 35  20   1 257  10   1  77]
 [ 39   3   0   9  50   0  21]
 [  2   2   0   0   0  21  12]
 [  0  15   9 109   3   3 486]]
=> Iteration 1:
Epoch 1:
[[259  11  13   4  30   0  75]
 [  6 261   2   1   4   0  42]
 [  1   3 139   0   0   0  58]
 [ 31   4   9 195  23   0 139]
 [ 24   3   0   0  41   0  54]
 [  1   2   0   0   0   5  29]
 [  8  17  15  79   1   0 505]]
Epoch 2:
[[279  11  11   5  17   0  69]
 [  2 271   1   2   3   0  37]
 [  1   3 141   4   0   0  52]
 [ 33   1   2 258   8   1  98]
 [ 32   5   0   6  27   0  52]
 [  1   1   0   0   1  15  19]
 [  0  15  11  93   1   1 504]]
Epoch 3:
[[293  16   9  12   6   0  56]
 [  6 289   1   6   0   0  14]
 [  2   4 121   7   0   0  67]
 [ 31   6   0 308   3   1  52]
 [ 40   7   0  16  25   0  34]
 [  1   2   0   0   0  18  16]
 [  1  23   2 110   1   1 487]]
Epoch 4:
[[306  11  12   6  12   0  45]
 [ 10 290   1   3   1   0  11]
 [  1   4 146   5   0   0  45]
 [ 34   8   3 259  12   1  84]
 [ 48   4   0  12  31   2  25]
 [  1   2   1   0   1  20  12]
 [  1  25  16  74   7   5 497]]
=> Iteration 2:
Epoch 1:
[[328   2  18   7   2   0  35]
 [ 23 242   1  15   0   0  35]
 [  2   2 147   7   0   0  43]
 [ 45   4   4 265   0   1  82]
 [ 64   4   8   9  12   4  21]
 [  5   2   1   4   0  10  15]
 [ 20   9  20  97   0   0 479]]
Epoch 2:
[[293   6  10   5   1   0  77]
 [  4 263   0  13   0   0  36]
 [  0   3 124   5   0   0  69]
 [ 33   7   0 233   7   1 120]
 [ 44   6   0   3  23   3  43]
 [  2   2   0   0   0  19  14]
 [  0  16   3  84   0   3 519]]
Epoch 3:
[[318   5  12   5  16   0  36]
 [  9 275   1   8   1   0  22]
 [  7   2 147   8   0   0  37]
 [ 34   9   2 288  12   1  55]
 [ 36   4   0   8  60   2  12]
 [  2   2   1   0   0  22  10]
 [  4  15  20 110   2   8 466]]
Epoch 4:
[[322   4  11   5  14   0  36]
 [  9 281   1   5   1   0  19]
 [  8   2 148   7   0   0  36]
 [ 35  13   2 276  10   2  63]
 [ 52   4   0  12  38   3  13]
 [  1   2   1   0   0  24   9]
 [  3  21  17  98   0   9 477]]
=> Iteration 3:
Epoch 1:
[[331   5  11   3   0   0  42]
 [ 34 249   1   0   0   0  32]
 [  6   2 142   0   0   0  51]
 [ 82   5  11 107   1   1 194]
 [ 68   3   0   0   0   3  48]
 [  7   1   0   0   0   8  21]
 [ 28  15  15  21   0   0 546]]
Epoch 2:
[[298  16  11   6   7   0  54]
 [  2 288   1   8   0   0  17]
 [  1   7 144   8   0   0  41]
 [ 37   8   5 282   6   1  62]
 [ 56  23   0  15  10   3  15]
 [  4   3   0   1   0  17  12]
 [  0  19  11 126   1   4 464]]
Epoch 3:
[[306   4  11   9   7   0  55]
 [  8 280   2   6   0   0  20]
 [  1   3 150   8   0   0  39]
 [ 37   6   6 284   5   1  62]
 [ 51   0   0  20  19   3  29]
 [  2   1   1   1   0  19  13]
 [  0  12  20 116   1   6 470]]
Epoch 4:
[[309   6  11   5  15   0  46]
 [  7 283   2   4   1   0  19]
 [  3   4 146   7   0   0  41]
 [ 40   7   6 258   9   1  80]
 [ 53   2   0  10  42   0  15]
 [  3   2   1   0   1  21   9]
 [  0  15  17  87   1   7 498]]
=> Iteration 4:
Epoch 1:
[[329  18   3   4   0   0  38]
 [ 19 260   1   7   0   0  29]
 [ 11   6 129   3   0   0  52]
 [ 43  14   5 188   0   0 151]
 [ 68  15   3   0   0   0  36]
 [  4   2   5   2   0   0  24]
 [ 12  81   6  68   0   0 458]]
Epoch 2:
[[272   7  12   5   6   0  90]
 [  2 252   1  14   0   0  47]
 [  0   2 128   4   0   0  67]
 [ 29   4   0 268   0   0 100]
 [ 34   4   7   6  19   0  52]
 [  2   1   1   1   0  10  22]
 [  0   7   4  94   0   0 520]]
Epoch 3:
[[312   6  13   4  15   0  42]
 [  6 276   1   2   1   0  30]
 [  8   4 143   5   0   0  41]
 [ 34  10   9 271  13   1  63]
 [ 40   3   6   5  50   1  17]
 [  2   1   0   0   0  24  10]
 [  0  33  19  99   0   7 467]]
Epoch 4:
[[320   6  10   4   9   0  43]
 [ 12 277   1   2   0   0  24]
 [ 10   5 139   6   0   0  41]
 [ 35   9   3 281  12   1  60]
 [ 57   3   4   6  36   0  16]
 [  3   2   0   0   0  22  10]
 [  1  32  19  94   0   6 473]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.431214   0.907624   0.535729   0.524952    0.521921
Iteration 1    1.447666   0.900756   0.729399   0.563384    0.591583
Iteration 2    1.422503   0.888400   0.739973   0.589969    0.607346
Iteration 3    1.407759   0.987806   0.620220   0.527926    0.529789
Iteration 4    1.414857   1.037711   0.493514   0.500784    0.488229

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.939928   0.935426   0.703650   0.620897    0.644268
Iteration 1    0.955669   0.816522   0.742497   0.621047    0.658996
Iteration 2    0.950928   0.864079   0.756496   0.615733    0.652471
Iteration 3    0.932164   0.809392   0.686266   0.625012    0.634891
Iteration 4    0.962716   0.885943   0.795921   0.579214    0.622868

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.762873   0.786951   0.751828   0.641168    0.676542
Iteration 1    0.793531   0.811315   0.783165   0.643240    0.678377
Iteration 2    0.788362   0.744433   0.741598   0.709003    0.722853
Iteration 3    0.771892   0.823708   0.718823   0.648920    0.663726
Iteration 4    0.788370   0.796970   0.730416   0.694611    0.708454

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.680054   0.758873   0.754982   0.676596    0.706848
Iteration 1    0.700544   0.776239   0.719015   0.665775    0.684120
Iteration 2    0.693938   0.740861   0.725783   0.694084    0.702606
Iteration 3    0.694174   0.771340   0.737312   0.680318    0.701327
Iteration 4    0.693501   0.782701   0.737724   0.675954    0.695672

