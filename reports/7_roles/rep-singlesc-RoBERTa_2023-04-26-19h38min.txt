RESULTS REPORT (SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Freeze layers: False
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h44m51s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.405616  0.008435  1.176699 0.035320   0.6191  0.0315   0.5179  0.0320   0.5365   0.0269
  2    1.126449  0.006572  1.113854 0.009407   0.6077  0.0156   0.5648  0.0096   0.5735   0.0122
  3    1.012019  0.007564  1.128574 0.010669   0.6044  0.0177   0.5736  0.0150   0.5744   0.0077
  4    0.934337  0.006264  1.141049 0.013653   0.5933  0.0086   0.5778  0.0070   0.5772   0.0069

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[320   9   3  10   8   1  41]
 [ 56 174   3  31   2   0  50]
 [ 25   6 133   6   2   1  28]
 [ 66  12  18 185   5   4 111]
 [ 58   6   3  13  16   5  21]
 [ 10   0   0   4   0  17   6]
 [109  31  13  61   5   9 397]]
Epoch 2:
[[288  13   1  10  17   4  59]
 [ 26 204   2  31   1   1  51]
 [ 10  10 128  12   0   1  40]
 [ 46  12  12 221   8   2 100]
 [ 38  11   0  17  22   9  25]
 [  1   0   0   4   1  23   8]
 [ 66  41   7 106   6  10 389]]
Epoch 3:
[[291  14   2   4  16   3  62]
 [ 23 219   4  22   1   0  47]
 [  8   9 137   5   0   0  42]
 [ 51  21  14 194   7   0 114]
 [ 33  12   3  10  30   6  28]
 [  1   0   0   4   3  20   9]
 [ 64  60  12  71   7   6 405]]
Epoch 4:
[[289  11   2   5  17   5  63]
 [ 21 208   5  28   1   1  52]
 [ 10   7 135   5   0   0  44]
 [ 50  13  16 197   7   1 117]
 [ 31  13   3  13  30   8  24]
 [  1   0   0   4   1  24   7]
 [ 61  54  16  73   7   9 405]]
=> Iteration 1:
Epoch 1:
[[284   4   0   6  15   4  79]
 [ 39 182   2  26   2   0  65]
 [  5   3 114   0   0   0  79]
 [ 49  10   7 154   6   0 175]
 [ 41   4   1   9  27   4  36]
 [  8   0   0   0   2  15  12]
 [ 64  15   1  42   4   2 497]]
Epoch 2:
[[286  13   0   7  22   4  60]
 [ 27 211   4  23   4   0  47]
 [  8   5 135   7   0   0  46]
 [ 49  15  13 193   7   0 124]
 [ 33  11   1   8  35   8  26]
 [  3   0   0   2   1  19  12]
 [ 54  41   3  67  12   4 444]]
Epoch 3:
[[273  17   8   8  16   9  61]
 [ 26 208   8  25   2   2  45]
 [  6   6 148   3   0   2  36]
 [ 46  14  22 192   7   2 118]
 [ 27  13   4   9  29  14  26]
 [  1   0   0   2   0  26   8]
 [ 49  35  24  71   6  17 423]]
Epoch 4:
[[278  14   5  13  16   4  62]
 [ 25 208   6  26   2   0  49]
 [  8   7 139   5   0   1  41]
 [ 46  14  17 201   6   0 117]
 [ 30  13   0  11  29  10  29]
 [  1   0   0   2   1  23  10]
 [ 51  38  12  80  10  11 423]]
=> Iteration 2:
Epoch 1:
[[194  17   1   4   1   3 172]
 [  9 181   1  22   0   0 103]
 [  0   3 111   2   0   0  85]
 [ 28  13   8 153   1   0 198]
 [ 16  11   2  10   4   7  72]
 [  1   0   0   0   0  12  24]
 [ 25  20   2  42   0   4 532]]
Epoch 2:
[[295  18   5   5  11   2  56]
 [ 22 217  10  26   1   0  40]
 [ 12   5 142   6   0   0  36]
 [ 46  23  25 204   7   0  96]
 [ 39  13   5  14  24   5  22]
 [  6   0   0   4   2  17   8]
 [ 69  56  29  92   4   8 367]]
Epoch 3:
[[284  14   2   7  15   3  67]
 [ 26 202   6  24   1   1  56]
 [ 10   4 134   3   0   0  50]
 [ 45  19  15 174   7   1 140]
 [ 36  12   1  11  27   8  27]
 [  2   0   0   0   1  22  12]
 [ 69  46   7  51   7   9 436]]
Epoch 4:
[[279  15   5  10  15   4  64]
 [ 23 203   6  28   1   1  54]
 [ 11   5 138   4   0   1  42]
 [ 45  14  16 205   7   1 113]
 [ 29  12   2  18  27  10  24]
 [  3   0   0   2   0  21  11]
 [ 57  53  18  74   7  12 404]]
=> Iteration 3:
Epoch 1:
[[266  31   1  14   8   5  67]
 [ 20 215   3  25   0   0  53]
 [ 11   8 127   6   0   0  49]
 [ 43  22  16 191   4   1 124]
 [ 32  21   0  22  13   6  28]
 [  6   0   0   1   2  15  13]
 [ 65  59   7  74   1   5 414]]
Epoch 2:
[[270   5   4  12  11   6  84]
 [ 27 186   2  32   0   1  68]
 [  7   3 133   7   0   1  50]
 [ 46  10  16 216   5   1 107]
 [ 31   6   1  16  26  10  32]
 [  3   0   0   4   3  21   6]
 [ 51  15  12 102   1  16 428]]
Epoch 3:
[[294  10   6   7   5   4  66]
 [ 33 200   6  24   1   0  52]
 [  8   7 134   4   0   0  48]
 [ 52  15  16 186   3   0 129]
 [ 39  10   2  13  20   7  31]
 [  4   0   0   4   2  18   9]
 [ 59  51  11  63   0   5 436]]
Epoch 4:
[[288  16   3   6  16   5  58]
 [ 27 207   6  23   2   0  51]
 [ 10   8 132   6   0   0  45]
 [ 49  16  15 200   4   0 117]
 [ 33  13   1  12  26  10  27]
 [  2   0   0   4   3  21   7]
 [ 59  49  11  74   6  11 415]]
=> Iteration 4:
Epoch 1:
[[271   3   5   4  17   8  84]
 [ 33 184   5  22   3   1  68]
 [  4   1 132   2   0   3  59]
 [ 46  13  14 140   9   0 179]
 [ 35   4   3   7  27   9  37]
 [  2   0   0   0   1  21  13]
 [ 55  12   5  32   2   9 510]]
Epoch 2:
[[311   5   1   3  11   5  56]
 [ 34 200   8  27   2   0  45]
 [ 13   4 131   5   0   0  48]
 [ 56  15  13 194   6   0 117]
 [ 50  10   1   8  21   4  28]
 [  5   0   0   2   2  17  11]
 [ 86  20  12  71   7   4 425]]
Epoch 3:
[[299  10   5   6  13   6  53]
 [ 30 215   9  23   3   0  36]
 [  9   5 135   5   0   1  46]
 [ 51  19  16 204   7   0 104]
 [ 40  12   2  11  21   9  27]
 [  3   0   0   4   0  22   8]
 [ 64  66  11  75   7  11 391]]
Epoch 4:
[[278  13   6   9  22   4  60]
 [ 24 212   9  26   3   0  42]
 [  7   5 135   6   0   1  47]
 [ 44  17  16 212   8   0 104]
 [ 32  13   6  12  27   7  25]
 [  2   0   0   4   1  23   7]
 [ 52  65  20  77  11  10 390]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.413170   1.210440   0.583013   0.530829    0.536829
Iteration 1    1.410293   1.146959   0.655061   0.524794    0.561279
Iteration 2    1.412830   1.220024   0.652975   0.458540    0.489048
Iteration 3    1.391669   1.177711   0.584164   0.520209    0.532016
Iteration 4    1.400116   1.128361   0.620427   0.554904    0.563465

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.125787   1.116978   0.592953   0.570364    0.570593
Iteration 1    1.121059   1.111939   0.626937   0.580150    0.596661
Iteration 2    1.122639   1.120678   0.586248   0.556834    0.560530
Iteration 3    1.123530   1.096605   0.612395   0.563316    0.568692
Iteration 4    1.139232   1.123073   0.620022   0.553343    0.571222

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.020995   1.120547   0.615272   0.576459    0.587677
Iteration 1    1.002672   1.119539   0.584728   0.598141    0.575489
Iteration 2    1.005703   1.136021   0.608173   0.568260    0.575381
Iteration 3    1.010081   1.146058   0.629650   0.551634    0.565720
Iteration 4    1.020647   1.120707   0.584201   0.573690    0.567834

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.934153   1.142182   0.602544   0.585848    0.585240
Iteration 1    0.928497   1.114976   0.601875   0.585190    0.585315
Iteration 2    0.927656   1.154563   0.586366   0.569601    0.568342
Iteration 3    0.936409   1.147994   0.595103   0.569987    0.572312
Iteration 4    0.944972   1.145531   0.580757   0.578189    0.574928

