RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 1.0
Augmentation rate: 1.0
Classes to augment: ['Fact', 'Argument', 'Statute', 'Precedent', 'RulingByLowerCourt', 'RulingByPresentCourt', 'RatioOfTheDecision']
Average number of mixup vectors by epoch: 14818.25
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h46m35s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.498588  0.013722  1.170941 0.025216   0.5940  0.0274   0.5180  0.0226   0.5293   0.0240
  2    1.275174  0.007519  1.123077 0.015651   0.5783  0.0119   0.5673  0.0101   0.5638   0.0087
  3    1.190331  0.005316  1.112889 0.019683   0.5918  0.0166   0.5673  0.0077   0.5687   0.0061
  4    1.129666  0.001412  1.111756 0.012507   0.5864  0.0033   0.5843  0.0093   0.5772   0.0057

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[308   9   6  10   6   2  51]
 [ 45 185   3  32   0   0  51]
 [ 25  11 125   4   0   1  35]
 [ 60  15  17 174   4   3 128]
 [ 53   7   3  13  14   7  25]
 [ 10   0   0   6   2  14   5]
 [ 94  47   7  63   0   9 405]]
Epoch 2:
[[297   7   3   5  21   7  52]
 [ 37 203   6  23   0   1  46]
 [ 10   5 137  10   0   1  38]
 [ 52  19  18 215   8   2  87]
 [ 35  10   5  13  26  12  21]
 [  1   0   0   4   1  24   7]
 [ 87  35  18 111   9  15 350]]
Epoch 3:
[[296   7   2   7  10   3  67]
 [ 30 193   9  29   0   0  55]
 [  9   4 138   5   0   1  44]
 [ 49  11  17 192   5   0 127]
 [ 46  10   1  14  21   7  23]
 [  4   0   0   4   0  21   8]
 [ 71  35  13  68   4   9 425]]
Epoch 4:
[[285  14   1   7  22   3  60]
 [ 26 206   7  29   3   1  44]
 [  9  11 135   6   0   1  39]
 [ 47  16  17 203   6   0 112]
 [ 33  13   1  10  31   9  25]
 [  1   0   0   4   1  25   6]
 [ 64  62  17  82   6  12 382]]
=> Iteration 1:
Epoch 1:
[[305   5   2   4   9   4  63]
 [ 52 179   5  24   3   0  53]
 [  7   2 136   2   0   0  54]
 [ 59   9  15 177   6   0 135]
 [ 45   5   2  13  21   4  32]
 [ 10   0   0   2   3  13   9]
 [ 87  18  10  59   3   3 445]]
Epoch 2:
[[298  13   8   9  15   3  46]
 [ 44 192  12  32   1   0  35]
 [  7   7 155   5   1   0  26]
 [ 49   9  26 216   7   0  94]
 [ 33  11   9  13  27   9  20]
 [  1   0   2   5   2  21   6]
 [ 90  39  43 109   6   8 330]]
Epoch 3:
[[296  15   1   7  16   4  53]
 [ 34 204   7  23   1   0  47]
 [  9   4 139   7   0   1  41]
 [ 60   9  16 215   4   0  97]
 [ 32  13   1  11  27   8  30]
 [  2   0   0   2   1  20  12]
 [ 75  37  10  90  10  10 393]]
Epoch 4:
[[287  15   3   8  19   5  55]
 [ 26 207   9  25   3   0  46]
 [  7   8 144   6   0   1  35]
 [ 49  13  18 217   6   0  98]
 [ 31  14   2   9  32  11  23]
 [  1   0   0   2   1  24   9]
 [ 62  53  18  87  11  11 383]]
=> Iteration 2:
Epoch 1:
[[233  18   4   2   2   4 129]
 [ 15 207   2  17   0   0  75]
 [  2   6 127   4   0   0  62]
 [ 42  19  12 147   2   0 179]
 [ 31  16   8   8   2   5  52]
 [  4   0   2   0   0  11  20]
 [ 41  40   7  37   0   5 495]]
Epoch 2:
[[250  16   7  21  27   5  66]
 [ 16 208  10  33   6   0  43]
 [  7   4 155   7   1   0  27]
 [ 40  17  22 220   9   1  92]
 [ 31  13   6  12  31   7  22]
 [  2   0   2   2   2  21   8]
 [ 44  41  30 109  18   7 376]]
Epoch 3:
[[288  15   7  16  17   4  45]
 [ 25 207   7  36   1   1  39]
 [  9   9 143   7   0   0  33]
 [ 47  16  17 220   5   0  96]
 [ 38  14   2  18  23   7  20]
 [  3   0   0   2   0  22  10]
 [ 70  57  14 110  13  10 351]]
Epoch 4:
[[273  17   4  13  21   5  59]
 [ 19 208   5  28   2   1  53]
 [  9   5 137   5   0   0  45]
 [ 43  18  15 202   5   1 117]
 [ 30  12   2  15  28   9  26]
 [  2   0   0   4   0  23   8]
 [ 58  61   6  84  14  12 390]]
=> Iteration 3:
Epoch 1:
[[271  21   5  15   6   6  68]
 [ 22 221   4  32   1   0  36]
 [ 12  11 137   6   0   0  35]
 [ 44  23  19 205   4   1 105]
 [ 34  17   4  27  11   7  22]
 [  5   2   0   5   2  16   7]
 [ 68  69  16  99   1   6 366]]
Epoch 2:
[[271   4   4  11  14   7  81]
 [ 22 183   5  31   0   0  75]
 [  6   3 134   6   0   0  52]
 [ 43  11  12 201   4   1 129]
 [ 32   9   2  17  17  12  33]
 [  1   0   1   4   0  22   9]
 [ 50  18  11  95   7  16 428]]
Epoch 3:
[[269  24   6  16  14   6  57]
 [ 23 219   6  32   2   0  34]
 [  8  10 145  10   0   0  28]
 [ 43  19  19 223   5   1  91]
 [ 30  17   5  14  26  10  20]
 [  1   0   1   5   0  22   8]
 [ 56  70  19 116   8  11 345]]
Epoch 4:
[[288  10   8   6  16   6  58]
 [ 29 200   8  25   3   1  50]
 [  7   6 148   6   0   0  34]
 [ 46  16  19 199   6   1 114]
 [ 37  12   2  10  25  11  25]
 [  0   0   0   4   0  26   7]
 [ 66  39  21  76   7  14 402]]
=> Iteration 4:
Epoch 1:
[[294   2   4   2   8   6  76]
 [ 38 189   5  19   5   1  59]
 [  5   1 126   2   0   3  64]
 [ 55  10  13 142   7   2 172]
 [ 45   4   2   2  25   9  35]
 [  8   0   0   0   0  19  10]
 [ 80  12   4  36   2   8 483]]
Epoch 2:
[[233  32   1   5  38   5  78]
 [ 16 219   4  26   3   0  48]
 [  6   6 125   9   0   0  55]
 [ 39  23  10 221  10   0  98]
 [ 21  13   1  13  39   4  31]
 [  2   0   0   2   1  19  13]
 [ 36  67   3 107  11   7 394]]
Epoch 3:
[[288   9   4  16  10   5  60]
 [ 22 208   6  36   1   0  43]
 [ 10   8 128  12   0   0  43]
 [ 48  15  11 229   6   0  92]
 [ 42  12   2  22  17   4  23]
 [  3   0   0   4   0  20  10]
 [ 49  52   8 131   8   6 371]]
Epoch 4:
[[283  12   5   9  16   4  63]
 [ 23 213   8  24   3   1  44]
 [  6   7 139   4   0   1  44]
 [ 48  17  16 209   7   1 103]
 [ 34  12   4  12  25   9  26]
 [  2   0   0   4   1  21   9]
 [ 57  49  17  86  10   9 397]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.500006   1.180218   0.578758   0.509728    0.517276
Iteration 1    1.496318   1.140268   0.623104   0.528288    0.552328
Iteration 2    1.523152   1.214215   0.577108   0.479081    0.492372
Iteration 3    1.481741   1.164489   0.560884   0.527386    0.526445
Iteration 4    1.491722   1.155515   0.629953   0.545759    0.557988

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.272040   1.128826   0.566605   0.577082    0.560618
Iteration 1    1.269310   1.133216   0.572109   0.570639    0.561156
Iteration 2    1.289753   1.105374   0.569197   0.577003    0.571589
Iteration 3    1.270109   1.104314   0.585471   0.551013    0.550509
Iteration 4    1.274657   1.143654   0.598313   0.560575    0.575003

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.191348   1.110666   0.614516   0.564419    0.572030
Iteration 1    1.180638   1.080011   0.602466   0.574147    0.579151
Iteration 2    1.196606   1.135248   0.574602   0.570650    0.565921
Iteration 3    1.192958   1.130880   0.571079   0.573782    0.563058
Iteration 4    1.190102   1.107639   0.596511   0.553471    0.563321

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.129743   1.117368   0.588245   0.585399    0.579159
Iteration 1    1.130081   1.096733   0.591285   0.595502    0.586731
Iteration 2    1.131429   1.132557   0.581839   0.573588    0.570831
Iteration 3    1.127099   1.109759   0.586622   0.593001    0.577258
Iteration 4    1.129978   1.102361   0.583759   0.573773    0.572091

