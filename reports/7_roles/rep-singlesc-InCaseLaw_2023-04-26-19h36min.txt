RESULTS REPORT (SINGLE SENTENCE CLASSIFICATION)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Freeze layers: False
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h44m53s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.233274  0.006297  1.004596 0.006588   0.6438  0.0163   0.6000  0.0123   0.6042   0.0103
  2    0.979243  0.002935  1.031813 0.004571   0.6373  0.0120   0.6013  0.0063   0.6001   0.0028
  3    0.874893  0.004068  1.053460 0.009911   0.6129  0.0111   0.6046  0.0046   0.5933   0.0071
  4    0.804806  0.005178  1.063297 0.008125   0.6220  0.0064   0.6088  0.0034   0.6028   0.0033

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[270   8   3   3   7   4  97]
 [ 17 208   2  27   1   0  61]
 [  5   1 122  10   0   0  63]
 [ 39   8   7 222   4   0 121]
 [ 27   7   1  13  22  12  40]
 [  2   0   0   0   0  23  12]
 [ 38  17   4  98   1   6 461]]
Epoch 2:
[[295  17   2   2   8   3  65]
 [ 16 236   1  16   2   0  45]
 [  3   4 126   5   0   0  63]
 [ 34  15   7 178   5   0 162]
 [ 29  12   2  13  22  11  33]
 [  1   1   0   0   0  24  11]
 [ 47  65   5  43   2   7 456]]
Epoch 3:
[[317  15   2   2   9   3  44]
 [ 22 230   2  23   2   1  36]
 [  7   3 135   8   0   0  48]
 [ 40  15  12 213   5   1 115]
 [ 35  11   1  12  22  15  26]
 [  1   1   0   2   0  27   6]
 [ 68  94   8  73   3  13 366]]
Epoch 4:
[[298  17   1   3  13   3  57]
 [ 19 230   2  21   2   1  41]
 [  5   4 131   7   0   0  54]
 [ 37  14   9 211   5   0 125]
 [ 28  11   1  11  28  11  32]
 [  1   1   0   2   0  26   7]
 [ 48  87   6  74   6  11 393]]
=> Iteration 1:
Epoch 1:
[[319  10   3   2   8   4  46]
 [ 27 214   4  25   1   0  45]
 [ 10   2 140   8   0   0  41]
 [ 45  10  13 217   4   0 112]
 [ 39   7   6  10  18  13  29]
 [  2   1   0   0   0  24  10]
 [ 61  60  10  80   2  11 401]]
Epoch 2:
[[317  13   0   9  10   3  40]
 [ 20 226   0  31   3   0  36]
 [  6   5 126  13   0   0  51]
 [ 39   7   8 222   6   0 119]
 [ 29  11   2  18  23  14  25]
 [  1   0   0   2   0  25   9]
 [ 58  61   2  90   9   8 397]]
Epoch 3:
[[312  16   3   3  15   4  39]
 [ 22 229   5  28   3   1  28]
 [  9   6 141  10   0   1  34]
 [ 36  16  18 209   6   0 116]
 [ 32  11   4   9  29  15  22]
 [  1   1   0   2   0  26   7]
 [ 58 102  16  68   8  11 362]]
Epoch 4:
[[315  14   1   6  13   4  39]
 [ 22 223   3  30   2   1  35]
 [  9   6 135  12   0   0  39]
 [ 36  12  10 220   6   0 117]
 [ 35  11   0  11  27  14  24]
 [  1   1   0   2   0  25   8]
 [ 53  76   7  80  12  11 386]]
=> Iteration 2:
Epoch 1:
[[300  16   4   8  11   3  50]
 [ 15 220   3  33   2   0  43]
 [ 10   2 138  12   0   0  39]
 [ 39   8  16 235   6   0  97]
 [ 25  10   5  17  29  13  23]
 [  1   1   0   0   0  24  11]
 [ 54  37  15 118   2   4 395]]
Epoch 2:
[[314  10   6   3  14   3  42]
 [ 23 220   8  21   3   0  41]
 [ 10   2 144   4   0   0  41]
 [ 42  10  16 190   4   0 139]
 [ 29  11   4  12  30  12  24]
 [  1   0   0   0   0  24  12]
 [ 69  39  25  56   4   9 423]]
Epoch 3:
[[286  19   3   6  15   3  60]
 [ 16 226   2  25   2   1  44]
 [ 10   5 132   5   0   0  49]
 [ 33  13  11 202   6   0 136]
 [ 25  15   3   6  34  14  25]
 [  1   1   0   0   0  26   9]
 [ 42  57  10  70   7  11 428]]
Epoch 4:
[[302  20   1   5  12   3  49]
 [ 18 230   2  26   2   1  37]
 [ 11   5 133   5   0   0  47]
 [ 36  13  11 205   6   0 130]
 [ 29  13   2   8  33  13  24]
 [  1   1   0   0   0  26   9]
 [ 53  71  10  70   7  11 403]]
=> Iteration 3:
Epoch 1:
[[300   8   9   5   9   3  58]
 [ 23 212   5  25   1   0  50]
 [  7   1 135   7   0   0  51]
 [ 42   8  11 218   4   0 118]
 [ 33   5   4   6  30  13  31]
 [  2   0   0   0   0  24  11]
 [ 45  30  10  90   1   8 441]]
Epoch 2:
[[315   9   2   3   9   4  50]
 [ 25 214   1  26   1   1  48]
 [  7   1 127   7   0   0  59]
 [ 43   9   7 198   4   0 140]
 [ 32   5   1  10  24  16  34]
 [  1   0   0   0   0  27   9]
 [ 57  41   3  73   3  13 435]]
Epoch 3:
[[311   9   5   5  11   3  48]
 [ 24 218   6  28   2   1  37]
 [  7   3 135   8   0   0  48]
 [ 38  11  13 212   3   0 124]
 [ 34   7   3  17  22  13  26]
 [  1   0   0   0   0  26  10]
 [ 66  49  12  89   4  11 394]]
Epoch 4:
[[302  12   4   3  17   3  51]
 [ 25 222   5  27   3   1  33]
 [  7   5 134   8   0   0  47]
 [ 37  12  12 208   5   0 127]
 [ 30  10   1   8  34  13  26]
 [  1   0   0   0   0  27   9]
 [ 57  74  10  79   7  11 387]]
=> Iteration 4:
Epoch 1:
[[276  13   2   7  20   4  70]
 [ 13 219   4  28   3   1  48]
 [  5   3 139   8   0   0  46]
 [ 29  10  11 210  10   1 130]
 [ 20   9   3  12  32  14  32]
 [  2   0   0   0   0  25  10]
 [ 33  29   5  83   4  13 458]]
Epoch 2:
[[307  27   0   2  12   4  40]
 [ 16 241   3  23   2   1  30]
 [  5   4 130   6   0   0  56]
 [ 36  17   8 198   5   0 137]
 [ 28  14   1  10  26  14  29]
 [  1   1   0   2   0  25   8]
 [ 44  90   4  62   7  12 406]]
Epoch 3:
[[296  27   4   5  11   3  46]
 [ 16 237   4  29   2   1  27]
 [  5   6 131  11   0   0  48]
 [ 35  18  10 232   6   0 100]
 [ 28  17   2  12  26  13  24]
 [  1   1   0   0   0  26   9]
 [ 41 124   6  97   8  10 339]]
Epoch 4:
[[315  16   0   5  11   3  42]
 [ 24 227   2  27   2   1  33]
 [  9   2 133   8   0   0  49]
 [ 36  13  10 210   6   0 126]
 [ 33  11   1  10  27  14  26]
 [  1   1   0   2   0  26   7]
 [ 49  70   6  81  14  11 394]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.223813   1.006783   0.666496   0.578162    0.596474
Iteration 1    1.240299   1.012720   0.623050   0.595206    0.587752
Iteration 2    1.228225   1.009456   0.638246   0.607495    0.611066
Iteration 3    1.238734   0.995069   0.658660   0.607375    0.614648
Iteration 4    1.235297   0.998954   0.632378   0.611875    0.611059

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.981874   1.026412   0.655096   0.589817    0.598253
Iteration 1    0.981669   1.040277   0.628745   0.600535    0.600220
Iteration 2    0.974624   1.030389   0.628841   0.608401    0.605010
Iteration 3    0.981128   1.031373   0.648267   0.604121    0.600422
Iteration 4    0.976922   1.030614   0.625653   0.603535    0.596837

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.876839   1.058006   0.615886   0.604999    0.589071
Iteration 1    0.881284   1.067925   0.596176   0.608986    0.590272
Iteration 2    0.869203   1.049924   0.628884   0.610204    0.607290
Iteration 3    0.874626   1.037691   0.617967   0.599570    0.591710
Iteration 4    0.872515   1.053756   0.605831   0.599088    0.587951

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.804216   1.063228   0.628978   0.603856    0.601779
Iteration 1    0.813670   1.060793   0.613423   0.606304    0.598164
Iteration 2    0.799893   1.078755   0.629971   0.612738    0.608013
Iteration 3    0.806686   1.057801   0.618239   0.612275    0.604364
Iteration 4    0.799564   1.055907   0.619160   0.608817    0.601526

