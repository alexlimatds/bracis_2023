RESULTS REPORT - DFCSC-SEP
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Dataset: malik
Evaluation: test set (5 random seeds)
Max sequence length: 512
Min context length: 250
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h33m44s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.241290  0.032769  0.861278 0.034196   0.6035  0.0626   0.5566  0.0171   0.5539   0.0250
  2    0.839016  0.010225  0.787715 0.017824   0.6692  0.0158   0.6309  0.0287   0.6342   0.0211
  3    0.722822  0.004470  0.783111 0.023064   0.6826  0.0130   0.6472  0.0078   0.6494   0.0065
  4    0.654257  0.004976  0.777385 0.025199   0.6880  0.0149   0.6544  0.0113   0.6589   0.0059

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
Argument: 1 
Statute: 2 
Precedent: 3 
RulingByLowerCourt: 4 
RulingByPresentCourt: 5 
RatioOfTheDecision: 6 
=> Iteration 0:
Epoch 1:
[[316  14   3   5   0   4  50]
 [  9 279   6   8   0   2  12]
 [  0   4 140   6   0   0  51]
 [ 46  25  11 231   0   0  88]
 [ 72   3   0  14  14   3  16]
 [  1   2   1   2   0   9  22]
 [  0  19  18 108   0  13 467]]
Epoch 2:
[[300  21   3   5   9   1  53]
 [  5 289   6   3   0   2  11]
 [  0   4 140   6   0   0  51]
 [ 46  29  11 198   0   0 117]
 [ 55   3   0  15  32   8   9]
 [  1   1   1   0   0  11  23]
 [  0  11  22  52   0  13 527]]
Epoch 3:
[[305  19   3   5   9   1  50]
 [  7 287   6   3   0   2  11]
 [  0   4 138   6   0   0  53]
 [ 46  29  10 226   0   5  85]
 [ 55   7   0  17  26   8   9]
 [  1   1   1   0   0  20  14]
 [  1  10  16  77   0  21 500]]
Epoch 4:
[[298  19   5   5  11   1  53]
 [  4 287   8   3   1   2  11]
 [  0   4 138   8   0   0  51]
 [ 46  29  10 249   0   5  62]
 [ 45   3   0  17  40   8   9]
 [  1   1   1   0   0  20  14]
 [  0  10  17  83   0  21 494]]
=> Iteration 1:
Epoch 1:
[[323  23   7  13  10   0  16]
 [  5 294   0   7   4   0   6]
 [  1   7 126  15   0   0  52]
 [ 46  27   4 285   0   0  39]
 [ 74   7   0  23   4   0  14]
 [  1   2   0  17   0   0  17]
 [ 18  19   9 166   2   0 411]]
Epoch 2:
[[293  21   7   7  32   2  30]
 [  4 290   4   4   5   2   7]
 [  0   6 132   6   0   1  56]
 [ 40  25   8 259   6   1  62]
 [ 44   7   0  12  42  13   4]
 [  1   2   0   3   0  23   8]
 [  0  19  16  66   2  22 500]]
Epoch 3:
[[290  24   8   5  31   1  33]
 [  1 293   4   3   5   0  10]
 [  0   6 134   6   0   1  54]
 [ 40  25  10 263   6   1  56]
 [ 44   7   0  17  37  13   4]
 [  1   2   0   3   0  17  14]
 [  0  19  15  68   2  16 505]]
Epoch 4:
[[299  21   7   5  31   1  28]
 [  5 290   4   3   5   0   9]
 [  0   6 135   6   0   1  53]
 [ 40  25   9 267   6   1  53]
 [ 44   7   0  17  37  13   4]
 [  1   2   0   3   0  17  14]
 [  0  19  17  74   2  16 497]]
=> Iteration 2:
Epoch 1:
[[341  12   5   5   3   0  26]
 [  9 286   5   3   5   0   8]
 [  1   6 136   6   0   0  52]
 [ 47  25  10 219   0   0 100]
 [ 67   3   0  10  23   0  19]
 [  1   2   1   5   0   0  28]
 [  6  15  21  62   5   0 516]]
Epoch 2:
[[308  19   1   5  21   0  38]
 [  4 286   6   3   9   0   8]
 [  0   4 133  12   2   0  50]
 [ 46  22   8 263   0   0  62]
 [ 48   3   0  15  47   0   9]
 [  1   2   1   5   0  11  17]
 [  0  15  21  87  11  10 481]]
Epoch 3:
[[321  19   1   5  11   0  35]
 [  6 286   6   3   5   0  10]
 [  1   4 127  14   2   0  53]
 [ 46  22   5 267   0   0  61]
 [ 48   3   0  19  38   5   9]
 [  1   2   1   3   0  11  19]
 [  1  15  12  71   7  10 509]]
Epoch 4:
[[323  19   1   5  11   1  32]
 [  7 286   6   3   5   0   9]
 [  0   4 130  14   0   0  53]
 [ 46  22   6 267   0   1  59]
 [ 45   3   0  19  38  13   4]
 [  1   2   1   1   0  15  17]
 [  1  15  13  76   2  12 506]]
=> Iteration 3:
Epoch 1:
[[299  25   2   5   8   0  53]
 [  5 293   0   3   0   0  15]
 [  0   8 118   6   0   0  69]
 [ 40  27   1 232   0   0 101]
 [ 58  10   0  10  20   0  24]
 [  1   2   0   5   0   0  29]
 [  0  34   8  73   0   0 510]]
Epoch 2:
[[297  19   5   5  12   1  53]
 [  4 290   4   3   1   0  14]
 [  0   7 132  10   0   0  52]
 [ 40  25   8 255   6   0  67]
 [ 45   3   0  15  42   8   9]
 [  1   2   0   3   0   1  30]
 [  0  18  15  85   0   6 501]]
Epoch 3:
[[304  14   5   5  12   1  51]
 [  5 288   7   3   1   2  10]
 [  0   6 136  12   0   0  47]
 [ 46  25   8 255   0   5  62]
 [ 49   3   0  17  36   8   9]
 [  1   2   1   0   0  20  13]
 [  0  29  17  87   0  21 471]]
Epoch 4:
[[292  19   5   5  12   1  58]
 [  4 288   6   3   1   0  14]
 [  0   6 133   6   0   0  56]
 [ 40  25   8 244   6   0  78]
 [ 45   3   0  15  42   8   9]
 [  1   2   0   0   0  13  21]
 [  0  18  15  67   0  10 515]]
=> Iteration 4:
Epoch 1:
[[325  12   2  16   3   0  34]
 [ 10 281   4  15   0   0   6]
 [  0   6 132  17   0   0  46]
 [ 40  16   7 326   0   0  12]
 [ 61   3   0  41   0   0  17]
 [  1   1   0  11   0   0  24]
 [  2   6  13 232   0   0 372]]
Epoch 2:
[[330  15   5   5   9   1  27]
 [ 10 289   8   3   1   2   3]
 [  0   4 139   6   0   0  52]
 [ 46  22  13 215   0   5 100]
 [ 64   3   0  15  17   8  15]
 [  1   2   1   0   0  20  13]
 [  2  19  17  60   0  21 506]]
Epoch 3:
[[310  22   5   5  13   1  36]
 [  4 291   7   3   2   0   9]
 [  0   6 137   6   0   0  52]
 [ 46  25  10 238   0   4  78]
 [ 48   7   0  15  33   8  11]
 [  1   2   1   0   0  18  15]
 [  0  23  17  53   0  16 516]]
Epoch 4:
[[317  15   5   5  13   1  36]
 [  5 289   8   3   2   0   9]
 [  0   4 139   6   0   0  52]
 [ 50  22   8 261   0   5  55]
 [ 48   7   0  15  33   8  11]
 [  1   2   1   0   0  20  13]
 [  1  19  17  68   0  18 502]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.210803   0.841883   0.695662   0.580973    0.586310
Iteration 1    1.236496   0.907583   0.544468   0.540334    0.527324
Iteration 2    1.229189   0.808230   0.620035   0.573120    0.575064
Iteration 3    1.225312   0.883590   0.633800   0.547932    0.557169
Iteration 4    1.304652   0.865107   0.523400   0.540458    0.523561

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.827369   0.802758   0.682870   0.610420    0.623224
Iteration 1    0.831211   0.807386   0.665495   0.676237    0.662101
Iteration 2    0.838984   0.763608   0.685375   0.637210    0.654134
Iteration 3    0.840502   0.769414   0.641189   0.591556    0.604792
Iteration 4    0.857016   0.795408   0.671267   0.639083    0.626574

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.722163   0.814565   0.684981   0.641443    0.636983
Iteration 1    0.725747   0.773945   0.657925   0.651468    0.649336
Iteration 2    0.715316   0.745127   0.694849   0.634970    0.653789
Iteration 3    0.722215   0.787760   0.683681   0.655522    0.651904
Iteration 4    0.728669   0.794158   0.691398   0.652770    0.655135

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.656808   0.817960   0.693492   0.662108    0.661010
Iteration 1    0.646026   0.783417   0.658336   0.653699    0.651114
Iteration 2    0.655221   0.739283   0.697110   0.652589    0.662578
Iteration 3    0.652285   0.771667   0.693823   0.635153    0.653015
Iteration 4    0.660945   0.774596   0.697275   0.668554    0.666557

