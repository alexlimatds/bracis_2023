RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: InCaseLaw
Encoder: law-ai/InCaseLawBERT
Dataset: facts
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 1.0
Augmentation rate: 1.0
Classes to augment: ['Fact', 'RulingByPresentCourt', 'RatioOfTheDecision']
Average number of mixup vectors by epoch: 8472.25
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h52m49s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.963708  0.005108  0.721230 0.010457   0.6184  0.0106   0.6458  0.0303   0.6223   0.0230
  2    0.828877  0.006406  0.711842 0.009346   0.6163  0.0112   0.6586  0.0086   0.6285   0.0119
  3    0.769529  0.006937  0.724565 0.007677   0.6130  0.0065   0.6642  0.0172   0.6288   0.0144
  4    0.728601  0.007720  0.728832 0.007066   0.6118  0.0053   0.6657  0.0056   0.6324   0.0055

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
RatioOfTheDecision: 2 
Other: 3 
=> Iteration 0:
Epoch 1:
[[304   3  42  43]
 [  1  23  12   1]
 [ 51   6 379 189]
 [118  12 255 758]]
Epoch 2:
[[285   3  32  72]
 [  1  26   6   4]
 [ 54  11 284 276]
 [ 79  16 164 884]]
Epoch 3:
[[302   3  30  57]
 [  1  26   6   4]
 [ 51  12 235 327]
 [ 94  15 137 897]]
Epoch 4:
[[286   3  43  60]
 [  1  26   6   4]
 [ 46  12 300 267]
 [ 83  16 195 849]]
=> Iteration 1:
Epoch 1:
[[269   4  75  44]
 [  2  24  11   0]
 [ 29   8 434 154]
 [ 88  13 272 770]]
Epoch 2:
[[272   3  35  82]
 [  1  25   6   5]
 [ 35  12 250 328]
 [ 84  14 118 927]]
Epoch 3:
[[295   3  57  37]
 [  1  25  11   0]
 [ 42  10 409 164]
 [116  13 254 760]]
Epoch 4:
[[280   3  48  61]
 [  1  26   8   2]
 [ 32  10 327 256]
 [ 97  14 190 842]]
=> Iteration 2:
Epoch 1:
[[267   3  40  82]
 [  0  25   6   6]
 [ 28  11 288 298]
 [ 73  15 133 922]]
Epoch 2:
[[256   2  83  51]
 [  1  25   8   3]
 [ 23   9 406 187]
 [ 76  12 253 802]]
Epoch 3:
[[279   3  44  66]
 [  1  26   7   3]
 [ 35  13 320 257]
 [ 86  16 189 852]]
Epoch 4:
[[280   3  43  66]
 [  1  26   7   3]
 [ 34  11 330 250]
 [ 93  15 186 849]]
=> Iteration 3:
Epoch 1:
[[276   4  34  78]
 [  1  26   5   5]
 [ 44  10 201 370]
 [ 86  15  90 952]]
Epoch 2:
[[276   3  46  67]
 [  1  26   9   1]
 [ 36  11 293 285]
 [ 83  14 173 873]]
Epoch 3:
[[260   3  38  91]
 [  1  26   7   3]
 [ 30  11 212 372]
 [ 71  15 102 955]]
Epoch 4:
[[286   3  46  57]
 [  1  26   7   3]
 [ 41  11 300 273]
 [ 88  15 174 866]]
=> Iteration 4:
Epoch 1:
[[277   2  33  80]
 [  1  20  10   6]
 [ 41   4 186 394]
 [ 85  12 114 932]]
Epoch 2:
[[280   3  34  75]
 [  1  27   8   1]
 [ 34  12 235 344]
 [ 86  16 134 907]]
Epoch 3:
[[283   3  55  51]
 [  0  25   7   5]
 [ 38  10 355 222]
 [ 94  16 205 828]]
Epoch 4:
[[278   3  46  65]
 [  0  25   8   4]
 [ 40  10 300 275]
 [ 91  16 169 867]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.956854   0.729552   0.619958   0.666675    0.639422
Iteration 1    0.964671   0.721105   0.631632   0.675735    0.647489
Iteration 2    0.970179   0.701434   0.627525   0.656062    0.632975
Iteration 3    0.958919   0.730054   0.609383   0.640320    0.606069
Iteration 4    0.967919   0.724004   0.603573   0.590043    0.585790

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.825293   0.719681   0.611012   0.664387    0.629099
Iteration 1    0.823610   0.695483   0.614712   0.645144    0.618241
Iteration 2    0.837305   0.708449   0.637551   0.670000    0.649258
Iteration 3    0.822251   0.714251   0.613226   0.659841    0.630075
Iteration 4    0.835924   0.721344   0.604761   0.653385    0.615670

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.769302   0.731764   0.603107   0.658472    0.618013
Iteration 1    0.762315   0.727056   0.622582   0.686886    0.647815
Iteration 2    0.780279   0.709638   0.609681   0.667961    0.631319
Iteration 3    0.762066   0.727463   0.613388   0.635172    0.607674
Iteration 4    0.773681   0.726903   0.616068   0.672506    0.639127

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.724158   0.732809   0.603651   0.663769    0.626331
Iteration 1    0.722241   0.719393   0.617353   0.669212    0.638211
Iteration 2    0.739844   0.722764   0.617231   0.671943    0.638530
Iteration 3    0.720919   0.739150   0.612939   0.667487    0.633378
Iteration 4    0.735840   0.730045   0.608055   0.655847    0.625712

