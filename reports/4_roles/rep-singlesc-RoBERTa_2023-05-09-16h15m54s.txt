RESULTS REPORT (SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Freeze layers: False
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h50m22s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    0.990847  0.015157  0.783489 0.010512   0.5961  0.0280   0.5111  0.0221   0.5174   0.0127
  2    0.819968  0.009377  0.753741 0.014794   0.6138  0.0103   0.5947  0.0271   0.5881   0.0274
  3    0.739440  0.010047  0.754684 0.017511   0.6197  0.0113   0.5966  0.0321   0.5992   0.0231
  4    0.680673  0.011034  0.763330 0.007203   0.6082  0.0035   0.6343  0.0103   0.6170   0.0070

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
RatioOfTheDecision: 2 
Other: 3 
=> Iteration 0:
Epoch 1:
[[ 216    1   20  155]
 [   3    9    9   16]
 [  36    2  197  390]
 [  56    3   84 1000]]
Epoch 2:
[[267   3  19 103]
 [  2  20   9   6]
 [ 47   7 127 444]
 [107   8  49 979]]
Epoch 3:
[[215   3  74 100]
 [  2  17  15   3]
 [ 37   3 355 230]
 [ 63   4 220 856]]
Epoch 4:
[[252   3  53  84]
 [  3  23   7   4]
 [ 44  11 317 253]
 [ 86  12 164 881]]
=> Iteration 1:
Epoch 1:
[[222  11  25 134]
 [  1  18   8  10]
 [ 29  16 194 386]
 [ 77  18  89 959]]
Epoch 2:
[[229   2  62  99]
 [  1  22   7   7]
 [ 16  11 400 198]
 [ 65  13 251 814]]
Epoch 3:
[[266   2  21 103]
 [  3  22   7   5]
 [ 50   7 165 403]
 [ 91  11  81 960]]
Epoch 4:
[[260   3  50  79]
 [  2  25   6   4]
 [ 39  11 307 268]
 [ 92  13 172 866]]
=> Iteration 2:
Epoch 1:
[[ 187    3   28  174]
 [   0   14   11   12]
 [  20    2  123  480]
 [  47   10   58 1028]]
Epoch 2:
[[267   2  42  81]
 [  0  21   8   8]
 [ 59   5 278 283]
 [ 92   8 146 897]]
Epoch 3:
[[260   2  49  81]
 [  1  23   8   5]
 [ 44   8 334 239]
 [ 88  11 200 844]]
Epoch 4:
[[252   2  53  85]
 [  1  23   8   5]
 [ 58   8 284 275]
 [ 82  10 156 895]]
=> Iteration 3:
Epoch 1:
[[279   3  22  88]
 [  7  11   9  10]
 [ 84   1 149 391]
 [119   5  74 945]]
Epoch 2:
[[223   3  33 133]
 [  1  23   9   4]
 [ 32  10 189 394]
 [ 65  14  85 979]]
Epoch 3:
[[247   2  56  87]
 [  2  21   9   5]
 [ 50  10 331 234]
 [ 78   8 191 866]]
Epoch 4:
[[271   2  52  67]
 [  1  23   9   4]
 [ 65  10 316 234]
 [ 95  11 173 864]]
=> Iteration 4:
Epoch 1:
[[263   2   6 121]
 [  5  13   7  12]
 [ 44   6  78 497]
 [112   2  42 987]]
Epoch 2:
[[291   2  21  78]
 [  5  15  12   5]
 [ 80   5 186 354]
 [125   3  90 925]]
Epoch 3:
[[207   2  47 136]
 [  1  19   9   8]
 [ 33   7 176 409]
 [ 50   4 101 988]]
Epoch 4:
[[261   3  43  85]
 [  3  23   7   4]
 [ 37   9 248 331]
 [ 83  13 138 909]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.980228   0.776914   0.642658   0.496089    0.530425
Iteration 1    1.000500   0.776279   0.554617   0.550558    0.529216
Iteration 2    0.968380   0.772123   0.596229   0.487902    0.504756
Iteration 3    0.993523   0.793635   0.591541   0.518551    0.522942
Iteration 4    1.011604   0.798494   0.595589   0.502647    0.499741

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.812143   0.768740   0.604776   0.570345    0.556726
Iteration 1    0.825891   0.740482   0.619577   0.632735    0.620993
Iteration 2    0.806037   0.734296   0.628861   0.619567    0.621074
Iteration 3    0.824430   0.753682   0.600287   0.587354    0.573499
Iteration 4    0.831341   0.771502   0.615482   0.563657    0.568104

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.727241   0.756382   0.640609   0.581209    0.605672
Iteration 1    0.746149   0.767634   0.606849   0.594265    0.580471
Iteration 2    0.728173   0.730394   0.617858   0.639424    0.627442
Iteration 3    0.743152   0.740453   0.614440   0.621231    0.617204
Iteration 4    0.752486   0.778558   0.618690   0.546892    0.565130

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.676428   0.766833   0.607709   0.635614    0.618076
Iteration 1    0.679418   0.767489   0.606941   0.646949    0.621857
Iteration 2    0.664272   0.751471   0.613322   0.625476    0.616595
Iteration 3    0.685285   0.759092   0.610238   0.643613    0.624315
Iteration 4    0.697962   0.771768   0.602909   0.619878    0.604194

