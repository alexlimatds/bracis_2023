RESULTS REPORT - Cohan
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Chunk layout: Cohan
Evaluation: test set (5 random seeds)
Max sequence length: 512
Max sentence length: 85
Max sentences per chunk: 7
Batch size: 16
Dropout rate: 0.2
Learning rate: 1e-05
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 00h33m57s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.025137  0.020112  0.736732 0.028077   0.5434  0.0618   0.5208  0.0426   0.5222   0.0467
  2    0.813167  0.014161  0.670248 0.023691   0.6705  0.0511   0.6279  0.0267   0.6358   0.0057
  3    0.717044  0.011410  0.661778 0.014869   0.6691  0.0160   0.6355  0.0132   0.6453   0.0123
  4    0.650531  0.009595  0.656923 0.028195   0.6689  0.0136   0.6387  0.0215   0.6481   0.0151

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
RatioOfTheDecision: 2 
Other: 3 
=> Iteration 0:
Epoch 1:
[[312   0  18  62]
 [  1   0   9  27]
 [ 22   0 366 237]
 [104   0 207 832]]
Epoch 2:
[[307   0  36  49]
 [  3  13   7  14]
 [ 15   7 368 235]
 [ 98   3 166 876]]
Epoch 3:
[[297   0  52  43]
 [  3  16   9   9]
 [  9   7 401 208]
 [ 90   6 206 841]]
Epoch 4:
[[310   0  47  35]
 [  4  18   8   7]
 [ 14  10 362 239]
 [100   4 185 854]]
=> Iteration 1:
Epoch 1:
[[305   1  34  52]
 [  1   8   6  22]
 [ 13   0 397 215]
 [ 95   6 186 856]]
Epoch 2:
[[249   0  33 110]
 [  1  11   4  21]
 [  0   0 381 244]
 [ 54   2 134 953]]
Epoch 3:
[[344   0  30  18]
 [  4  13   9  11]
 [ 34   7 390 194]
 [134   6 196 807]]
Epoch 4:
[[297   0  46  49]
 [  4  11   8  14]
 [  8   1 394 222]
 [ 86   5 196 856]]
=> Iteration 2:
Epoch 1:
[[314   0  19  59]
 [  4   0  18  15]
 [ 55   0 378 192]
 [114   0 237 792]]
Epoch 2:
[[296   0  61  35]
 [  1  20  14   2]
 [ 17  16 502  90]
 [ 96  16 338 693]]
Epoch 3:
[[287   0  41  64]
 [  1  17   9  10]
 [ 11   3 330 281]
 [ 83   7 114 939]]
Epoch 4:
[[292   0  55  45]
 [  2  20  11   4]
 [ 11   4 400 210]
 [ 94   8 209 832]]
=> Iteration 3:
Epoch 1:
[[292   0  21  79]
 [  1   0  13  23]
 [ 14   0 203 408]
 [ 78   0  83 982]]
Epoch 2:
[[310   0  44  38]
 [  4  12  11  10]
 [ 14  10 434 167]
 [100   5 246 792]]
Epoch 3:
[[315   0  46  31]
 [  4  11   8  14]
 [ 13   4 377 231]
 [113   3 182 845]]
Epoch 4:
[[314   0  41  37]
 [  4  12   8  13]
 [ 15   7 381 222]
 [100   4 198 841]]
=> Iteration 4:
Epoch 1:
[[234   0  29 129]
 [  1   0  12  24]
 [  0   0 272 353]
 [ 43   0 108 992]]
Epoch 2:
[[299   0  36  57]
 [  3  12   9  13]
 [ 12   5 413 195]
 [ 79   8 214 842]]
Epoch 3:
[[317   0  51  24]
 [  3  15   9  10]
 [ 14   7 422 182]
 [108   4 219 812]]
Epoch 4:
[[312   0  51  29]
 [  4  15  10   8]
 [ 14   9 438 164]
 [ 92   5 235 811]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.988109   0.697285   0.509797   0.527357    0.517904
Iteration 1    1.036426   0.734062   0.663721   0.594596    0.612246
Iteration 2    1.020297   0.785271   0.493275   0.524683    0.506533
Iteration 3    1.036366   0.732622   0.512748   0.482210    0.481647
Iteration 4    1.044486   0.734421   0.537506   0.475008    0.492454

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.785864   0.656177   0.668734   0.622430    0.638793
Iteration 1    0.816539   0.640044   0.768268   0.593968    0.643568
Iteration 2    0.827195   0.710052   0.625081   0.676285    0.636401
Iteration 3    0.818057   0.679617   0.636429   0.625614    0.626519
Iteration 4    0.818182   0.665349   0.654003   0.621134    0.633545

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.697843   0.659132   0.665059   0.641867    0.651403
Iteration 1    0.716379   0.686456   0.643540   0.639735    0.634290
Iteration 2    0.732872   0.653035   0.693653   0.635281    0.658321
Iteration 3    0.715662   0.642392   0.671944   0.610838    0.627050
Iteration 4    0.722466   0.667874   0.671500   0.649923    0.655231

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.633165   0.684709   0.660138   0.650915    0.654419
Iteration 1    0.648932   0.643097   0.690244   0.608564    0.633174
Iteration 2    0.659902   0.696554   0.678006   0.663337    0.669563
Iteration 3    0.651983   0.631690   0.652304   0.617682    0.628730
Iteration 4    0.658671   0.628565   0.663673   0.652915    0.654598

