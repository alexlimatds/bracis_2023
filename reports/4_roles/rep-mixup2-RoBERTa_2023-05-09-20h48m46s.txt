RESULTS REPORT (MIXUP 2 SINGLE SENTENCE CLASSIFICATION)
Model: RoBERTa
Encoder: roberta-base
Dataset: facts
Evaluation: test set (5 random seeds)
Max sequence length: 512
Batch size: 16
Dropout rate: 0.2
Learning rate : 1e-05
Number of epochs: 4
Mixup alpha: 1.0
Augmentation rate: 1.0
Classes to augment: ['Fact', 'RulingByPresentCourt', 'RatioOfTheDecision']
Average number of mixup vectors by epoch: 8479.25
Adam Epsilon: 1e-08
Weight decay: 0.001
Train time: 02h53m31s
GPU name: Tesla V100-SXM2-16GB
GPU memory: 15.78

Averages:
Epoch Train loss   std    Test loss   std    P (macro) P std  R (macro) R std  F1 (macro) F1 std
  1    1.050942  0.017473  0.796563 0.022274   0.5993  0.0565   0.5366  0.0315   0.5391   0.0150
  2    0.911539  0.011071  0.757817 0.012994   0.6166  0.0186   0.6169  0.0060   0.6131   0.0112
  3    0.848744  0.011491  0.753710 0.011675   0.6090  0.0083   0.6174  0.0226   0.6078   0.0094
  4    0.805207  0.008949  0.753330 0.006075   0.5982  0.0091   0.6400  0.0073   0.6155   0.0076

*** Detailed report ***

Confusion matrices
------------------
Fact: 0 
RulingByPresentCourt: 1 
RatioOfTheDecision: 2 
Other: 3 
=> Iteration 0:
Epoch 1:
[[227   0  34 131]
 [  6   7  12  12]
 [ 37   0 226 362]
 [ 72   1 103 967]]
Epoch 2:
[[245   3  57  87]
 [  2  20  12   3]
 [ 34   8 334 249]
 [ 73   6 181 883]]
Epoch 3:
[[249   3  50  90]
 [  2  22   9   4]
 [ 37  11 284 293]
 [ 83  10 142 908]]
Epoch 4:
[[258   3  66  65]
 [  3  23   8   3]
 [ 55  11 321 238]
 [ 96  10 194 843]]
=> Iteration 1:
Epoch 1:
[[263  14  25  90]
 [  3  19   7   8]
 [ 54  21 238 312]
 [106  25 103 909]]
Epoch 2:
[[251   6  89  46]
 [  3  18  12   4]
 [ 45   7 393 180]
 [ 99   8 266 770]]
Epoch 3:
[[269   2  38  83]
 [  4  20  10   3]
 [ 56   8 255 306]
 [106   9 142 886]]
Epoch 4:
[[268   2  48  74]
 [  2  25   7   3]
 [ 42  10 318 255]
 [101  12 177 853]]
=> Iteration 2:
Epoch 1:
[[223   3  52 114]
 [  0  13  12  12]
 [ 31   1 215 378]
 [ 62   7 102 972]]
Epoch 2:
[[215   3  82  92]
 [  0  22  10   5]
 [ 15   6 387 217]
 [ 61   9 247 826]]
Epoch 3:
[[288   3  35  66]
 [  1  25   7   4]
 [ 76  11 274 264]
 [130  10 142 861]]
Epoch 4:
[[267   3  49  73]
 [  1  23  10   3]
 [ 67   9 309 240]
 [107  12 176 848]]
=> Iteration 3:
Epoch 1:
[[295   3  38  56]
 [  7  11  11   8]
 [ 84   3 225 313]
 [141   5 117 880]]
Epoch 2:
[[282   2  43  65]
 [  3  20  10   4]
 [ 64  10 279 272]
 [106   9 174 854]]
Epoch 3:
[[290   2  53  47]
 [  3  19  13   2]
 [ 62   7 369 187]
 [136   8 228 771]]
Epoch 4:
[[278   2  53  59]
 [  3  22  10   2]
 [ 64  14 331 216]
 [106  15 192 830]]
=> Iteration 4:
Epoch 1:
[[307   2   9  74]
 [ 10  11   7   9]
 [ 95   7 165 358]
 [158   5 116 864]]
Epoch 2:
[[276   3  64  49]
 [  3  18  15   1]
 [ 52   5 436 132]
 [123   5 318 697]]
Epoch 3:
[[260   3  47  82]
 [  2  18  11   6]
 [ 46   5 243 331]
 [ 96   4 129 914]]
Epoch 4:
[[265   5  57  65]
 [  2  22  11   2]
 [ 43  13 360 209]
 [ 95  12 224 812]]

Scores
------
Epoch: 1
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    1.035161   0.791397   0.699585   0.493973    0.530305
Iteration 1    1.067041   0.802876   0.546276   0.590127    0.546499
Iteration 2    1.026623   0.758623   0.617551   0.528656    0.556469
Iteration 3    1.054604   0.802757   0.583825   0.544938    0.547783
Iteration 4    1.071278   0.827164   0.549055   0.525092    0.514223

Epoch: 2
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.904342   0.742320   0.631784   0.618117    0.624156
Iteration 1    0.916885   0.769436   0.594824   0.607315    0.598814
Iteration 2    0.895488   0.745981   0.636613   0.621231    0.624381
Iteration 3    0.912920   0.755537   0.593403   0.613371    0.600652
Iteration 4    0.928060   0.775809   0.626233   0.624492    0.617348

Epoch: 3
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.834988   0.741237   0.609036   0.619650    0.609848
Iteration 1    0.856024   0.745181   0.599379   0.602480    0.596356
Iteration 2    0.836625   0.772959   0.602694   0.650513    0.618326
Iteration 3    0.851036   0.760957   0.610153   0.629563    0.616898
Iteration 4    0.865049   0.748214   0.623588   0.584550    0.597383

Epoch: 4
             Train loss  Test loss  P (macro)  R (macro)  F1 (macro)
Iteration 0    0.794543   0.758363   0.598562   0.632729    0.613461
Iteration 1    0.810572   0.746079   0.614282   0.653608    0.630332
Iteration 2    0.794721   0.757825   0.597493   0.634763    0.612929
Iteration 3    0.809677   0.745717   0.586531   0.639884    0.608218
Iteration 4    0.816522   0.758664   0.593967   0.639257    0.612780

